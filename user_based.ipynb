{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a8f664",
   "metadata": {},
   "source": [
    "# Custom User-based Model\n",
    "The present notebooks aims at creating a UserBased class that inherits from the Algobase class (surprise package) and that can be customized with various similarity metrics, peer groups and score aggregation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d1b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "0            1       31     2.5  1260759144\n",
      "1            1     1029     3.0  1260759179\n",
      "2            1     1061     3.0  1260759182\n",
      "3            1     1129     2.0  1260759185\n",
      "4            1     1172     4.0  1260759205\n",
      "...        ...      ...     ...         ...\n",
      "99999      671     6268     2.5  1065579370\n",
      "100000     671     6269     4.0  1065149201\n",
      "100001     671     6365     4.0  1070940363\n",
      "100002     671     6385     2.5  1070979663\n",
      "100003     671     6565     3.5  1074784724\n",
      "\n",
      "[100004 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# reloads modules automatically before entering the execution of code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# standard library imports\n",
    "# -- add new imports here --\n",
    "\n",
    "# third parties imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from surprise import AlgoBase\n",
    "# -- add new imports here --\n",
    "\n",
    "# local imports\n",
    "from constants import Constant as C\n",
    "from loaders import load_ratings\n",
    "# -- add new imports here --\n",
    "from surprise import Dataset, KNNWithMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "###\n",
    "import heapq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22716aa3",
   "metadata": {},
   "source": [
    "# 1. Loading Data\n",
    "Prepare a dataset in order to help implementing a user-based recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3ccdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load data, build trainset and anti testset --\n",
    "ratings = load_ratings(surprise_format=True)\n",
    "trainset = ratings.build_full_trainset()\n",
    "anti_testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adf3a6",
   "metadata": {},
   "source": [
    "# 2. Explore Surprise's user-based algorithm\n",
    "Displays user-based predictions and similarity matrix on the test dataset using the KNNWithMeans class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fb78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Prédiction pour l'utilisateur 11 et l'élément 364 : 4.252920516369196\n",
      "Utilisateur 1 a évalué l'élément 10 avec une note de 2.62 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 17 avec une note de 3.19 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 39 avec une note de 2.53 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 47 avec une note de 2.98 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 50 avec une note de 4.04 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 52 avec une note de 2.13 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 62 avec une note de 2.77 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 110 avec une note de 2.70 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 144 avec une note de 2.13 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 150 avec une note de 1.80 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 153 avec une note de 2.13 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 161 avec une note de 2.67 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 165 avec une note de 3.06 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 168 avec une note de 2.86 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 185 avec une note de 2.41 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 186 avec une note de 1.54 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 208 avec une note de 1.23 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 222 avec une note de 2.61 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 223 avec une note de 3.44 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 225 avec une note de 1.91 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 235 avec une note de 2.23 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 248 avec une note de 1.78 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 253 avec une note de 2.77 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 261 avec une note de 2.41 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 265 avec une note de 2.72 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 266 avec une note de 3.00 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 272 avec une note de 3.39 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 273 avec une note de 2.20 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 292 avec une note de 1.92 (actual_k = 3)\n",
      "Utilisateur 1 a évalué l'élément 296 avec une note de 3.65 (actual_k = 3)\n",
      "\n",
      "--- Aperçu de la matrice de similarité utilisateur-utilisateur ---\n",
      "Similarités de l'utilisateur interne 0 avec les autres : [1.         0.         0.         0.1980198  0.         0.\n",
      " 0.18867925 0.         0.         0.        ]\n",
      "Similarités de l'utilisateur interne 1 avec les autres : [0.         1.         0.45714286 0.34883721 0.54545455 0.\n",
      " 0.53125    0.48648649 0.54545455 0.        ]\n",
      "Similarités de l'utilisateur interne 2 avec les autres : [0.         0.45714286 1.         0.3255814  0.43636364 0.26666667\n",
      " 0.33587786 0.50704225 0.4137931  0.625     ]\n",
      "Similarités de l'utilisateur interne 3 avec les autres : [0.1980198  0.34883721 0.3255814  1.         0.40860215 0.4516129\n",
      " 0.37614679 0.43548387 0.25       0.36363636]\n",
      "Similarités de l'utilisateur interne 4 avec les autres : [0.         0.54545455 0.43636364 0.40860215 1.         0.84210526\n",
      " 0.51282051 0.46153846 0.44444444 0.        ]\n",
      "Similarités de l'utilisateur interne 5 avec les autres : [0.         0.         0.26666667 0.4516129  0.84210526 1.\n",
      " 0.         0.21621622 0.         0.10344828]\n",
      "Similarités de l'utilisateur interne 6 avec les autres : [0.18867925 0.53125    0.33587786 0.37614679 0.51282051 0.\n",
      " 1.         0.48598131 0.5        0.57894737]\n",
      "Similarités de l'utilisateur interne 7 avec les autres : [0.         0.48648649 0.50704225 0.43548387 0.46153846 0.21621622\n",
      " 0.48598131 1.         0.35714286 0.32835821]\n",
      "Similarités de l'utilisateur interne 8 avec les autres : [0.         0.54545455 0.4137931  0.25       0.44444444 0.\n",
      " 0.5        0.35714286 1.         0.5       ]\n",
      "Similarités de l'utilisateur interne 9 avec les autres : [0.         0.         0.625      0.36363636 0.         0.10344828\n",
      " 0.57894737 0.32835821 0.5        1.        ]\n",
      "\n",
      "La matrice de similarité a été sauvegardée dans 'similarity_matrix.csv'.\n"
     ]
    }
   ],
   "source": [
    "# -- using surprise's user-based algorithm, explore the impact of different parameters and displays predictions --\n",
    "sim_options = {\n",
    "    'name': 'msd',  \n",
    "    'user_based': True,  \n",
    "    'min_support': 3  \n",
    "}\n",
    "\n",
    "algo = KNNWithMeans(k=3, min_k=2, sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "prediction = algo.predict(uid=11, iid=364)\n",
    "print(f\"Prédiction pour l'utilisateur 11 et l'élément 364 : {prediction.est}\")\n",
    "\n",
    "\n",
    "predictions = algo.test(anti_testset)\n",
    "for pred in predictions[:30]:\n",
    "    print(f\"Utilisateur {pred.uid} a évalué l'élément {pred.iid} avec une note de {pred.est:.2f} (actual_k = {pred.details.get('actual_k', 'N/A')})\")\n",
    "\n",
    "    \n",
    "# Similarity matrix \n",
    "print(\"\\n--- Aperçu de la matrice de similarité utilisateur-utilisateur ---\")\n",
    "sim_matrix = algo.sim  \n",
    "n_max = min(10, sim_matrix.shape[0])  \n",
    "for i in range(n_max):\n",
    "    print(f\"Similarités de l'utilisateur interne {i} avec les autres : {sim_matrix[i, :n_max]}\")\n",
    "\n",
    "# Stockage de la matrice de similarité dans un fichier CSV\n",
    "sim_df = pd.DataFrame(sim_matrix)\n",
    "sim_df.to_csv(\"similarity_matrix.csv\", index=False)\n",
    "print(\"\\nLa matrice de similarité a été sauvegardée dans 'similarity_matrix.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7f18c",
   "metadata": {},
   "source": [
    "observations minK: \n",
    "\n",
    "- observations minK 2 par rapport à 1 sont similaire ou légerement plus elevé :Cela s'explique par le fait que l’algorithme impose une faible  contraintes sur le nombre minimum de voisins requis pour effectuer une prédiction. Avec des valeurs faibles de min_k, comme 1 ou 2, les prédictions peuvent être faites même avec très peu de voisins ce qui explique la faible variation entre les deux cas.\n",
    "Cependant, pour certaines prédictions où le nombre de voisins disponibles est inférieur à 2, l’algorithme utilise une valeur par défaut.\n",
    "\n",
    "- observation mink= 3: on augmente le nombre minimum de voisins requis pour faire une prédiction ce qui rend l’algorithme plus strict.\n",
    "Dans les 30 premières prédictions observées la majorité des valeurs restent similaires mais plusieurs prédictions augmentent, notamment celle de l'utilisateur 11 pour l’élément 364. Cette hausse est due au fait qu’il n’y avait pas assez de voisins (moins de 3) pour faire une prédiction personnalisée. L’algorithme a donc utilisé une valeur par défaut par exemple  ce qui peut expliquer l’augmentation.\n",
    "\n",
    "observations min support: \n",
    "\n",
    "- Plus la valeur de min_support est élevée, plus actual_k a tendance à diminuer.Cela s'explique par le fait qu’un min_support plus grand impose un critère plus strict : chaque voisin doit avoir au moins ce nombre d’évaluations communes avec l’utilisateur cible (par exemple, min_support = 3 signifie qu'il doit avoir au moins 3 évaluations communes avec l'utilisateur cible pour être pris en compte dans le calcul).Ainsi, moins de voisins respectent cette condition  ce qui réduit le nombre de voisins utilisables pour la prédiction et donc reduit le actual_k. \n",
    "\n",
    "- La variable actual_k représente le nombre de voisins qui ont réellement contribué à la prédiction.Plus actual_k est élevé, plus la prédiction est considérée comme fiable car elle repose sur un plus grand nombre d’avis pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd01f5b",
   "metadata": {},
   "source": [
    "# 3. Implement and explore a customizable user-based algorithm\n",
    "Create a self-made user-based algorithm allowing to customize the similarity metric, peer group calculation and aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c2b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBased(AlgoBase):\n",
    "    def __init__(self, k=3, min_k=1, sim_options={}, **kwargs):\n",
    "        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        \n",
    "        self.compute_rating_matrix()\n",
    "        \n",
    "        self.compute_similarity_matrix()\n",
    "        \n",
    "        self.mean_ratings = []\n",
    "        for u in range(self.trainset.n_users):\n",
    "            user_ratings = []\n",
    "            for (_, rating) in self.trainset.ur[u]: \n",
    "                user_ratings.append(rating)\n",
    "            if user_ratings:\n",
    "                mean_rating = np.mean(user_ratings)\n",
    "            else:\n",
    "                mean_rating = float('nan')  \n",
    "            self.mean_ratings.append(mean_rating)\n",
    "\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "            if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "                raise np.nan \n",
    "            \n",
    "            estimate = self.mean_ratings[u]\n",
    "\n",
    "            \n",
    "            neighbors = []\n",
    "            for (v, rating) in self.trainset.ir[i]:  \n",
    "                if v == u:\n",
    "                    continue  \n",
    "\n",
    "                sim_uv = self.sim[u, v] \n",
    "\n",
    "                if sim_uv > 0 and not np.isnan(self.ratings_matrix[v, i]): \n",
    "                    mean_v = self.mean_ratings[v]  \n",
    "                    neighbors.append((sim_uv, rating - mean_v))\n",
    "\n",
    "            \n",
    "            top_k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda x: x[0])\n",
    "\n",
    "            \n",
    "            actual_k = 0\n",
    "            weighted_sum = 0.0\n",
    "            sum_sim = 0.0\n",
    "\n",
    "            for sim, rating_diff in top_k_neighbors:\n",
    "                if actual_k == self.k:\n",
    "                    break\n",
    "                weighted_sum += sim * rating_diff\n",
    "                sum_sim += sim\n",
    "                actual_k += 1\n",
    "\n",
    "            # Check\n",
    "            if actual_k >= self.min_k and sum_sim > 0:\n",
    "                estimate += weighted_sum / sum_sim\n",
    "\n",
    "            return estimate\n",
    "\n",
    "\n",
    "                            \n",
    "    def compute_rating_matrix(self):\n",
    "        # -- implement here the compute_rating_matrix function --\n",
    "        self.ratings_matrix = np.empty((self.trainset.n_users, self.trainset.n_items))\n",
    "        self.ratings_matrix[:] = np.nan\n",
    "        for u in range(self.trainset.n_users): \n",
    "            for i, rating in self.trainset.ur[u]:\n",
    "                self.ratings_matrix[u, i] = rating\n",
    "\n",
    "    \n",
    "    def compute_similarity_matrix(self):\n",
    "        m = self.trainset.n_users\n",
    "        ratings_matrix = self.ratings_matrix\n",
    "        min_support = self.sim_options.get('min_support', 1)\n",
    "        sim_name = self.sim_options.get(\"name\", \"msd\") \n",
    "\n",
    "        # Similarity matrix\n",
    "        self.sim = np.eye(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(i + 1, m):  \n",
    "                row_i = ratings_matrix[i]\n",
    "                row_j = ratings_matrix[j]\n",
    "\n",
    "                if sim_name == \"jaccard\":\n",
    "                    sim = self.jaccard_similarity(row_i, row_j)\n",
    "                    support = np.sum(~np.isnan(row_i) & ~np.isnan(row_j))\n",
    "                elif sim_name == \"msd\":\n",
    "                    diff = row_i - row_j\n",
    "                    support = np.sum(~np.isnan(diff))\n",
    "                    if support >= min_support:\n",
    "                        msd = np.nanmean((diff[~np.isnan(diff)]) ** 2)\n",
    "                        sim = 1 / (1 + msd)\n",
    "                    else:\n",
    "                        sim = 0\n",
    "                else:\n",
    "                    \n",
    "                    diff = row_i - row_j\n",
    "                    support = np.sum(~np.isnan(diff))\n",
    "                    if support >= min_support:\n",
    "                        msd = np.nanmean((diff[~np.isnan(diff)]) ** 2)\n",
    "                        sim = 1 / (1 + msd)\n",
    "                    else:\n",
    "                        sim = 0\n",
    "\n",
    "                if support >= min_support:\n",
    "                    self.sim[i, j] = sim\n",
    "                    self.sim[j, i] = sim\n",
    "\n",
    "    def jaccard_similarity(self, row_i, row_j):\n",
    "        \n",
    "        mask_i = ~np.isnan(row_i)\n",
    "        mask_j = ~np.isnan(row_j)\n",
    "\n",
    "        intersection = np.sum(mask_i & mask_j)\n",
    "        union = np.sum(mask_i | mask_j)\n",
    "\n",
    "        if union == 0:\n",
    "            return 0.0\n",
    "        return intersection / union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc9cfe",
   "metadata": {},
   "source": [
    "# 4. Compare KNNWithMeans with UserBased\n",
    "Try to replicate KNNWithMeans with your self-made UserBased and check that outcomes are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be53ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  UID   IID   KNN est.  UserBased est.       Diff\n",
      "--------------------------------------------------\n",
      "    1    10     2.6248          2.6248     0.0000\n",
      "    1    17     3.1901          3.1901     0.0000\n",
      "    1    39     2.5295          2.5295     0.0000\n",
      "    1    47     2.9796          2.9796     0.0000\n",
      "    1    50     4.0432          4.0432     0.0000\n",
      "    1    52     2.1271          2.1271     0.0000\n",
      "    1    62     2.7740          2.7740     0.0000\n",
      "    1   110     2.6954          2.6954     0.0000\n",
      "    1   144     2.1305          2.1305     0.0000\n",
      "    1   150     1.8002          1.8002     0.0000\n",
      "    1   153     2.1304          2.1304     0.0000\n",
      "    1   161     2.6733          2.6733     0.0000\n",
      "    1   165     3.0645          3.0645     0.0000\n",
      "    1   168     2.8552          2.8552     0.0000\n",
      "    1   185     2.4117          2.4117     0.0000\n",
      "    1   186     1.5386          1.5386     0.0000\n",
      "    1   208     1.2282          1.2282     0.0000\n",
      "    1   222     2.6069          2.6069     0.0000\n",
      "    1   223     3.4423          3.4423     0.0000\n",
      "    1   225     1.9068          1.9068     0.0000\n",
      "    1   235     2.2323          2.2323     0.0000\n",
      "    1   248     1.7779          1.7779     0.0000\n",
      "    1   253     2.7663          2.7663     0.0000\n",
      "    1   261     2.4071          2.4071     0.0000\n",
      "    1   265     2.7224          2.7224     0.0000\n",
      "    1   266     2.9955          2.9955     0.0000\n",
      "    1   272     3.3870          3.3870     0.0000\n",
      "    1   273     2.2009          2.2009     0.0000\n",
      "    1   292     1.9189          1.9189     0.0000\n",
      "    1   296     3.6455          3.6455     0.0000\n"
     ]
    }
   ],
   "source": [
    "# -- assert that predictions are the same with different sim_options --\n",
    "#comparaison entre requltat KNNwithKmeans et resultqts user based \n",
    "import surprise\n",
    "from surprise import accuracy\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'msd',\n",
    "    'user_based': True,\n",
    "    'min_support': 3\n",
    "}\n",
    "k = 3\n",
    "min_k = 2\n",
    "\n",
    "\n",
    "userbased_algo = UserBased(k=k, min_k=min_k, sim_options=sim_options)\n",
    "userbased_algo.fit(trainset)\n",
    "\n",
    "\n",
    "knn_algo = KNNWithMeans(k=k, min_k=min_k, sim_options=sim_options)\n",
    "knn_algo.fit(trainset)\n",
    "\n",
    "\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "\n",
    "\n",
    "print(f\"{'UID':>5} {'IID':>5} {'KNN est.':>10} {'UserBased est.':>15} {'Diff':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (uid, iid, _) in enumerate(anti_testset[:30]):\n",
    "    pred_knn = knn_algo.predict(uid, iid)\n",
    "    pred_userbased = userbased_algo.predict(uid, iid)\n",
    "\n",
    "    diff = abs(pred_knn.est - pred_userbased.est)\n",
    "\n",
    "    print(f\"{uid:>5} {iid:>5} {pred_knn.est:10.4f} {pred_userbased.est:15.4f} {diff:10.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced76d9",
   "metadata": {},
   "source": [
    "# 5. Compare MSD and Jacard\n",
    "Compare predictions made with MSD similarity and Jacard similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20d8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UID   IID userbased_algo2 est.  UserBased est.       Diff\n",
      "--------------------------------------------------\n",
      "    1    10     2.6248          2.4304     0.1944\n",
      "    1    17     3.1901          3.3088     0.1187\n",
      "    1    39     2.5295          2.0776     0.4519\n",
      "    1    47     2.9796          2.9232     0.0565\n",
      "    1    50     4.0432          3.0949     0.9483\n",
      "    1    52     2.1271          2.2279     0.1007\n",
      "    1    62     2.7740          2.5136     0.2604\n",
      "    1   110     2.6954          3.2296     0.5342\n",
      "    1   144     2.1305          2.9085     0.7780\n",
      "    1   150     1.8002          2.0321     0.2319\n",
      "    1   153     2.1304          1.3591     0.7713\n",
      "    1   161     2.6733          2.5791     0.0942\n",
      "    1   165     3.0645          2.2383     0.8262\n",
      "    1   168     2.8552          2.0951     0.7602\n",
      "    1   185     2.4117          2.1663     0.2454\n",
      "    1   186     1.5386          1.8044     0.2658\n",
      "    1   208     1.2282          1.3135     0.0853\n",
      "    1   222     2.6069          2.6278     0.0210\n",
      "    1   223     3.4423          2.2588     1.1835\n",
      "    1   225     1.9068          2.2045     0.2976\n",
      "    1   235     2.2323          1.8506     0.3817\n",
      "    1   248     1.7779          1.8547     0.0768\n",
      "    1   253     2.7663          2.3438     0.4226\n",
      "    1   261     2.4071          2.5143     0.1073\n",
      "    1   265     2.7224          2.2724     0.4500\n",
      "    1   266     2.9955          2.0047     0.9908\n",
      "    1   272     3.3870          2.9050     0.4820\n",
      "    1   273     2.2009          2.3714     0.1706\n",
      "    1   292     1.9189          2.6304     0.7115\n",
      "    1   296     3.6455          4.4937     0.8482\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "from surprise import accuracy\n",
    "\n",
    "sim_options_userbased = {\n",
    "    'name': 'jaccard',\n",
    "    'user_based': True,\n",
    "    'min_support': 3\n",
    "}\n",
    "\n",
    "sim_options_userbased2 = {\n",
    "    'name': 'msd',\n",
    "    'user_based': True,\n",
    "    'min_support': 3\n",
    "}\n",
    "k = 3\n",
    "min_k = 2\n",
    "\n",
    "\n",
    "userbased_algo = UserBased(k=k, min_k=min_k, sim_options=sim_options_userbased)\n",
    "userbased_algo.fit(trainset)\n",
    "\n",
    "\n",
    "userbased_algo2 = UserBased(k=k, min_k=min_k, sim_options=sim_options_userbased2)\n",
    "userbased_algo2.fit(trainset)\n",
    "\n",
    "\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "\n",
    "print(f\"{'UID':>5} {'IID':>5} {'userbased_algo2 est.':>10} {'UserBased est.':>15} {'Diff':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (uid, iid, _) in enumerate(anti_testset[:30]):\n",
    "    pred_userbased_algo2 = userbased_algo2.predict(uid, iid)\n",
    "    pred_userbased = userbased_algo.predict(uid, iid)\n",
    "\n",
    "    diff = abs(pred_userbased_algo2.est - pred_userbased.est)\n",
    "\n",
    "    print(f\"{uid:>5} {iid:>5} {pred_userbased_algo2.est:10.4f} {pred_userbased.est:15.4f} {diff:10.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
