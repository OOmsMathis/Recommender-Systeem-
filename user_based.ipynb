{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a8f664",
   "metadata": {},
   "source": [
    "# Custom User-based Model\n",
    "The present notebooks aims at creating a UserBased class that inherits from the Algobase class (surprise package) and that can be customized with various similarity metrics, peer groups and score aggregation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d1b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloads modules automatically before entering the execution of code\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "# standard library imports\n",
    "# -- add new imports here --\n",
    "\n",
    "# third parties imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from surprise import AlgoBase\n",
    "# -- add new imports here --\n",
    "\n",
    "# local imports\n",
    "from constants import Constant as C\n",
    "from loaders import load_ratings\n",
    "# -- add new imports here --\n",
    "from surprise import Dataset, KNNWithMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "###\n",
    "import heapq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22716aa3",
   "metadata": {},
   "source": [
    "# 1. Loading Data\n",
    "Prepare a dataset in order to help implementing a user-based recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3ccdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load data, build trainset and anti testset --\n",
    "ratings = load_ratings(surprise_format=True)\n",
    "trainset = ratings.build_full_trainset()\n",
    "anti_testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adf3a6",
   "metadata": {},
   "source": [
    "# 2. Explore Surprise's user-based algorithm\n",
    "Displays user-based predictions and similarity matrix on the test dataset using the KNNWithMeans class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Prédiction pour l'utilisateur 11 et l'élément 364 : 2.49203431372549\n",
      "Utilisateur 11 a évalué l'élément 1214 avec une note de 3.60 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 11 a évalué l'élément 364 avec une note de 2.49 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 11 a évalué l'élément 4308 avec une note de 1.60 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 11 a évalué l'élément 527 avec une note de 3.90 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 13 a évalué l'élément 1997 avec une note de 2.80 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 13 a évalué l'élément 4993 avec une note de 3.24 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 13 a évalué l'élément 2700 avec une note de 2.80 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 13 a évalué l'élément 1721 avec une note de 1.24 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 13 a évalué l'élément 527 avec une note de 3.24 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 17 a évalué l'élément 2028 avec une note de 3.81 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 17 a évalué l'élément 4993 avec une note de 4.13 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 17 a évalué l'élément 1214 avec une note de 3.69 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 17 a évalué l'élément 4308 avec une note de 1.69 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 19 a évalué l'élément 1997 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 2028 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 4993 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 5952 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 2700 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 1721 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 1214 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 19 a évalué l'élément 364 avec une note de 3.50 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 23 a évalué l'élément 1997 avec une note de 2.78 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 23 a évalué l'élément 2700 avec une note de 2.35 (réel : 3.1333333333333333, actual_k = 2)\n",
      "Utilisateur 27 a évalué l'élément 1997 avec une note de 4.67 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 27 a évalué l'élément 2028 avec une note de 5.00 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 27 a évalué l'élément 5952 avec une note de 5.00 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 27 a évalué l'élément 2700 avec une note de 4.67 (réel : 3.1333333333333333, actual_k = 0)\n",
      "Utilisateur 27 a évalué l'élément 1721 avec une note de 3.10 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 27 a évalué l'élément 364 avec une note de 4.60 (réel : 3.1333333333333333, actual_k = 1)\n",
      "Utilisateur 27 a évalué l'élément 4308 avec une note de 3.10 (réel : 3.1333333333333333, actual_k = 1)\n"
     ]
    }
   ],
   "source": [
    "# -- using surprise's user-based algorithm, explore the impact of different parameters and displays predictions --\n",
    "sim_options = {\n",
    "    'name': 'msd',  # Mean Squared Difference\n",
    "    'user_based': True,  # Modèle basé sur les utilisateurs\n",
    "    'min_support': 3  # Minimum de 3 évaluations communes\n",
    "}\n",
    "# Créer une instance de KNNWithMeans\n",
    "algo = KNNWithMeans(k=3, min_k=2, sim_options=sim_options)\n",
    "# Entraîner le modèle\n",
    "algo.fit(trainset)\n",
    "# Faire une prédiction pour l'utilisateur 11 et l'élément 364\n",
    "prediction = algo.predict(uid=11, iid=364)\n",
    "print(f\"Prédiction pour l'utilisateur 11 et l'élément 364 : {prediction.est}\")\n",
    "\n",
    "\n",
    "predictions = algo.test(anti_testset)\n",
    "for pred in predictions[:30]:\n",
    "    print(f\"Utilisateur {pred.uid} a évalué l'élément {pred.iid} avec une note de {pred.est:.2f} (réel : {pred.r_ui}, actual_k = {pred.details.get('actual_k', 'N/A')})\")\n",
    "#1.La valeur de min_support est fixée à 3, ce qui signifie que pour qu'un voisin soit pris en compte dans le calcul de la prédiction il doit avoir au moins 3 évaluations communes avec l'utilisateur cible. Cela peut réduire le nombre de voisins valides et donc influencer la prédiction finale.\n",
    "#2.Quand min_support est fixé à 3, la valeur de actual_k diminue pour certaines prédictions. Cela est dû au fait que actual_k représente le nombre de voisins qui ont réellement été utilisés pour calculer la prédiction et l'augmentation de min_support réduit le nombre de voisins valides\n",
    "\n",
    "# Afficher une partie de la matrice de similarité (exemple pour les 10 premiers utilisateurs)\n",
    "#print(\"\\n--- Aperçu de la matrice de similarité utilisateur-utilisateur ---\")\n",
    "#sim_matrix = algo.sim  # Matrice numpy carrée (n_users x n_users)\n",
    "\n",
    "# Afficher une partie de la matrice de similarité (exemple pour les 10 premiers utilisateurs)\n",
    "#print(\"\\n--- Aperçu de la matrice de similarité utilisateur-utilisateur ---\")\n",
    "#sim_matrix = algo.sim  # Matrice numpy carrée (n_users x n_users)\n",
    "#n_max = min(10, sim_matrix.shape[0])  # On ne dépasse pas la taille réelle\n",
    "#for i in range(n_max):\n",
    " #   print(f\"Similarités de l'utilisateur interne {i} avec les autres : {sim_matrix[i, :n_max]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7f18c",
   "metadata": {},
   "source": [
    "observations minK:\n",
    "\n",
    "- observations minK 2 par rapport à 1 sont similaire ou légerement plus elevé :Cela s'explique par le fait que l’algorithme impose une faible  contraintes sur le nombre minimum de voisins requis pour effectuer une prédiction. Avec des valeurs faibles de min_k, comme 1 ou 2, les prédictions peuvent être faites même avec très peu de voisins ce qui explique la faible variation entre les deux cas.\n",
    "Cependant, pour certaines prédictions où le nombre de voisins disponibles est inférieur à 2, l’algorithme utilise une valeur par défaut comme la moyenne des évaluations de l’utilisateur ou la moyenne globale.\n",
    "\n",
    "- observation mink= 3: on augmente le nombre minimum de voisins requis pour faire une prédiction ce qui rend l’algorithme plus strict.\n",
    "Dans les 30 premières prédictions observées la majorité des valeurs restent similaires mais plusieurs prédictions augmentent, notamment celle de l'utilisateur 11 pour l’élément 364. Cette hausse est due au fait qu’il n’y avait pas assez de voisins (moins de 3) pour faire une prédiction personnalisée. L’algorithme a donc utilisé une valeur par défaut par exemple (moyenne des évaluations de l'utilisateur ou la moyenne globale) ce qui peut expliquer l’augmentation.\n",
    "\n",
    "observations min support: \n",
    "\n",
    "- Plus la valeur de min_support est élevée, plus actual_k a tendance à diminuer.Cela s'explique par le fait qu’un min_support plus grand impose un critère plus strict : chaque voisin doit avoir au moins ce nombre d’évaluations communes avec l’utilisateur cible (par exemple, min_support = 3 signifie au moins 3 évaluations communes).Ainsi, moins de voisins respectent cette condition  ce qui réduit le nombre de voisins utilisables pour la prédiction et donc reduit le actual_k. \n",
    "\n",
    "- La variable actual_k représente le nombre de voisins qui ont réellement contribué à la prédiction.Plus actual_k est élevé, plus la prédiction est considérée comme fiable, car elle repose sur un plus grand nombre d’avis pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd01f5b",
   "metadata": {},
   "source": [
    "# 3. Implement and explore a customizable user-based algorithm\n",
    "Create a self-made user-based algorithm allowing to customize the similarity metric, peer group calculation and aggregation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6de27c",
   "metadata": {},
   "source": [
    "changement de sort a heapq "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b9a4a",
   "metadata": {},
   "source": [
    "erreur dans le calcul du msd (trouver avec chat l'erreur de calcul)\n",
    "\n",
    "remplacement par np.nan  dans estimate \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7c2b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBased(AlgoBase):\n",
    "    def __init__(self, k=3, min_k=1, sim_options={}, **kwargs):\n",
    "        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        # Calcul de la matrice des ratings\n",
    "        self.compute_rating_matrix()\n",
    "        # Calcul de la matrice de similarité\n",
    "        self.compute_similarity_matrix()\n",
    "        # Calcul de la moyenne des notes par utilisateur\n",
    "        self.mean_ratings = []\n",
    "        for u in range(self.trainset.n_users):\n",
    "            user_ratings = []\n",
    "            for (_, rating) in self.trainset.ur[u]: #_ correspond à l'index de l'item\n",
    "                user_ratings.append(rating)\n",
    "            if user_ratings:\n",
    "                mean_rating = np.mean(user_ratings)\n",
    "            else:\n",
    "                mean_rating = float('nan')  # ou 0.0 si tu préfères éviter les NaN\n",
    "            self.mean_ratings.append(mean_rating)\n",
    "\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "            if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "                raise np.nan \n",
    "            \n",
    "            estimate = self.mean_ratings[u]\n",
    "\n",
    "            ## Obtenir les voisins de l'utilisateur u qui ont noté l'item i\n",
    "            neighbors = []\n",
    "            for (v, rating) in self.trainset.ir[i]:  \n",
    "                if v == u:\n",
    "                    continue  # ne pas se comparer à soi-même\n",
    "\n",
    "                sim_uv = self.sim[u, v]  # similarité entre u et v\n",
    "\n",
    "                if sim_uv > 0 and not np.isnan(self.ratings_matrix[v, i]):  # si la similarité est positive et que v a noté l'item i\n",
    "                    mean_v = self.mean_ratings[v]  # moyenne des notes de v\n",
    "                    neighbors.append((sim_uv, rating - mean_v))\n",
    "\n",
    "            # Trier les voisins par similarité décroissante\n",
    "            top_k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda x: x[0])\n",
    "\n",
    "            # Calcul de la moyenne pondérée sur les k meilleurs voisins\n",
    "            actual_k = 0\n",
    "            weighted_sum = 0.0\n",
    "            sum_sim = 0.0\n",
    "\n",
    "            for sim, rating_diff in top_k_neighbors:\n",
    "                if actual_k == self.k:\n",
    "                    break\n",
    "                weighted_sum += sim * rating_diff\n",
    "                sum_sim += sim\n",
    "                actual_k += 1\n",
    "\n",
    "            # Vérifier si on a suffisamment de voisins\n",
    "            if actual_k >= self.min_k and sum_sim > 0:\n",
    "                estimate += weighted_sum / sum_sim\n",
    "\n",
    "            return estimate\n",
    "\n",
    "\n",
    "                            \n",
    "    def compute_rating_matrix(self):\n",
    "        # -- implement here the compute_rating_matrix function --\n",
    "        self.ratings_matrix = np.empty((self.trainset.n_users, self.trainset.n_items))\n",
    "        self.ratings_matrix[:] = np.nan\n",
    "        for u in range(self.trainset.n_users): # or each user\n",
    "            for i, rating in self.trainset.ur[u]: #for each item rated by the user\n",
    "                self.ratings_matrix[u, i] = rating\n",
    "\n",
    "    \n",
    "    def compute_similarity_matrix(self):\n",
    "        m = self.trainset.n_users\n",
    "        ratings_matrix = self.ratings_matrix\n",
    "        min_support = self.sim_options.get('min_support', 1)\n",
    "        sim_name = self.sim_options.get(\"name\", \"euclidean\")  # valeur par défaut\n",
    "\n",
    "        # Initialiser la matrice de similarité\n",
    "        self.sim = np.eye(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(i + 1, m):  # j > i pour éviter les doublons\n",
    "                row_i = ratings_matrix[i]\n",
    "                row_j = ratings_matrix[j]\n",
    "\n",
    "                if sim_name == \"jaccard\":\n",
    "                    sim = self.jaccard_similarity(row_i, row_j)\n",
    "                    support = np.sum(~np.isnan(row_i) & ~np.isnan(row_j))\n",
    "\n",
    "                else:\n",
    "                    # Par défaut : similarité euclidienne normalisée\n",
    "                    diff = row_i - row_j\n",
    "                    support = np.sum(~np.isnan(diff))\n",
    "                    if support >= min_support:\n",
    "                        msd = np.nanmean((diff[~np.isnan(diff)]) ** 2)\n",
    "                        sim = 1 / (1 + msd)\n",
    "                    else:\n",
    "                        sim = 0\n",
    "\n",
    "                if support >= min_support:\n",
    "                    self.sim[i, j] = sim\n",
    "                    self.sim[j, i] = sim\n",
    "\n",
    "    def jaccard_similarity(self, row_i, row_j):\n",
    "        # Masques binaires : True là où il y a une note\n",
    "        mask_i = ~np.isnan(row_i)\n",
    "        mask_j = ~np.isnan(row_j)\n",
    "\n",
    "        intersection = np.sum(mask_i & mask_j)\n",
    "        union = np.sum(mask_i | mask_j)\n",
    "\n",
    "        if union == 0:\n",
    "            return 0.0\n",
    "        return intersection / union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc9cfe",
   "metadata": {},
   "source": [
    "# 4. Compare KNNWithMeans with UserBased\n",
    "Try to replicate KNNWithMeans with your self-made UserBased and check that outcomes are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be53ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  UID   IID   KNN est.  UserBased est.       Diff\n",
      "--------------------------------------------------\n",
      "   11  1214     3.1667          3.1667     0.0000\n",
      "   11   364     2.4920          2.4920     0.0000\n",
      "   11  4308     3.1667          3.1667     0.0000\n",
      "   11   527     3.8989          3.8989     0.0000\n",
      "   13  1997     2.8000          2.8000     0.0000\n",
      "   13  4993     2.8000          2.8000     0.0000\n",
      "   13  2700     2.8000          2.8000     0.0000\n",
      "   13  1721     2.8000          2.8000     0.0000\n",
      "   13   527     2.8000          2.8000     0.0000\n",
      "   17  2028     3.8125          3.8125     0.0000\n",
      "   17  4993     4.1283          4.1283     0.0000\n",
      "   17  1214     3.2500          3.2500     0.0000\n",
      "   17  4308     3.2500          3.2500     0.0000\n",
      "   19  1997     3.5000          3.5000     0.0000\n",
      "   19  2028     3.5000          3.5000     0.0000\n",
      "   19  4993     3.5000          3.5000     0.0000\n",
      "   19  5952     3.5000          3.5000     0.0000\n",
      "   19  2700     3.5000          3.5000     0.0000\n",
      "   19  1721     3.5000          3.5000     0.0000\n",
      "   19  1214     3.5000          3.5000     0.0000\n",
      "   19   364     3.5000          3.5000     0.0000\n",
      "   23  1997     2.7826          2.7826     0.0000\n",
      "   23  2700     2.3498          2.3498     0.0000\n",
      "   27  1997     4.6667          4.6667     0.0000\n",
      "   27  2028     4.6667          4.6667     0.0000\n",
      "   27  5952     4.6667          4.6667     0.0000\n",
      "   27  2700     4.6667          4.6667     0.0000\n",
      "   27  1721     4.6667          4.6667     0.0000\n",
      "   27   364     4.6667          4.6667     0.0000\n",
      "   27  4308     4.6667          4.6667     0.0000\n"
     ]
    }
   ],
   "source": [
    "# -- assert that predictions are the same with different sim_options --\n",
    "#comparaison entre requltat Kmeans et resultqts user based \n",
    "import surprise\n",
    "from surprise import accuracy\n",
    "\n",
    "# Paramètres de similarité\n",
    "sim_options = {\n",
    "    'name': 'msd',\n",
    "    'user_based': True,\n",
    "    'min_support': 3\n",
    "}\n",
    "k = 3\n",
    "min_k = 2\n",
    "\n",
    "# Ton algorithme custom\n",
    "userbased_algo = UserBased(k=k, min_k=min_k, sim_options=sim_options)\n",
    "userbased_algo.fit(trainset)\n",
    "\n",
    "# Algo officiel de surprise\n",
    "knn_algo = KNNWithMeans(k=k, min_k=min_k, sim_options=sim_options)\n",
    "knn_algo.fit(trainset)\n",
    "\n",
    "# Anti-testset (les notes absentes dans le trainset)\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "\n",
    "# Comparer les 30 premières prédictions\n",
    "print(f\"{'UID':>5} {'IID':>5} {'KNN est.':>10} {'UserBased est.':>15} {'Diff':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (uid, iid, _) in enumerate(anti_testset[:30]):\n",
    "    pred_knn = knn_algo.predict(uid, iid)\n",
    "    pred_userbased = userbased_algo.predict(uid, iid)\n",
    "\n",
    "    diff = abs(pred_knn.est - pred_userbased.est)\n",
    "\n",
    "    print(f\"{uid:>5} {iid:>5} {pred_knn.est:10.4f} {pred_userbased.est:15.4f} {diff:10.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced76d9",
   "metadata": {},
   "source": [
    "# 5. Compare MSD and Jacard\n",
    "Compare predictions made with MSD similarity and Jacard similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- compare predictions made with MSD similarity and Jacard similarity --\n",
    "# -- compare predictions made with MSD similarity and Jacard similarity --\n",
    "sim_options = {\"name\": \"jacard\", \"min_support\": 1}\n",
    "algo = UserBased(k=3, min_k=1, sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "predictions_jacard = algo.test(anti_testset)\n",
    "print(f\"Prédictions avec la similarité Jacard : {predictions_jacard[:30]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
