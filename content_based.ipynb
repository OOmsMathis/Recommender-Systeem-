{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d5ca82",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277473a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "from surprise import AlgoBase\n",
    "from surprise.prediction_algorithms.predictions import PredictionImpossible\n",
    "\n",
    "from loaders import load_ratings\n",
    "from loaders import load_items\n",
    "from constants import Constant as C\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c16bf",
   "metadata": {},
   "source": [
    "# Explore and select content features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8378976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = load_items()\n",
    "df_ratings = load_ratings()\n",
    "\n",
    "\n",
    "# Example 1 : create title_length features\n",
    "df_features = df_items[C.LABEL_COL].apply(lambda x: len(x)).to_frame('n_character_title')\n",
    "display(df_features.head())\n",
    "\n",
    "# 2. Year_of_release\n",
    "df_features = df_items[C.LABEL_COL].str.extract(r'\\((\\d{4})\\)')[0].astype('Int64').to_frame('release_year')\n",
    "display(df_features.head())\n",
    "\n",
    "# 3. Genre_list\n",
    "df_genre_list = df_items[C.GENRES_COL].str.split('|').to_frame('genre_list')\n",
    "display(df_genre_list.head())\n",
    "\n",
    "# 4. Genre_one_hot_encoding\n",
    " #Étape 1 : Exploser les listes de genres\n",
    "df_exploded = df_genre_list.explode('genre_list')\n",
    "# Étape 2 : Créer les variables dummies (one-hot encoding)\n",
    "df_dummies = pd.get_dummies(df_exploded['genre_list'])\n",
    "# Étape 3 : Reformer le DataFrame initial avec les one-hot encodings regroupés par index\n",
    "df_genres = df_dummies.groupby(df_exploded.index).sum()\n",
    "# Assure-toi que l'index corresponde à celui de df_items si nécessaire :\n",
    "df_genres = df_genres.reindex(df_items.index).fillna(0).astype(int)\n",
    "display(df_genres.head())\n",
    "# (explore here other features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9a2b6",
   "metadata": {},
   "source": [
    "# Build a content-based model\n",
    "When ready, move the following class in the *models.py* script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContentBased(AlgoBase):\n",
    "    def __init__(self, features_method, regressor_method):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.features_method = features_method \n",
    "        self.regressor_method = regressor_method\n",
    "        self.content_features = self.create_content_features(features_method)\n",
    "\n",
    "        \n",
    "\n",
    "    def create_content_features(self, features_methods):\n",
    "        \"\"\"Content Analyzer\"\"\"\n",
    "        df_items = load_items()\n",
    "        df_features = pd.DataFrame(index=df_items.index)\n",
    "        if features_methods is None:\n",
    "            df_features = pd.DataFrame(index=df_items.index)\n",
    "        if isinstance(features_methods, str):\n",
    "            features_methods = [features_methods]\n",
    "        \n",
    "        for feature_method in features_methods:\n",
    "\n",
    "            if feature_method == \"title_length\":\n",
    "                df_title_length = df_items[C.LABEL_COL].apply(lambda x: len(x)).to_frame('title_length')\n",
    "                df_title_length['title_length'] = df_title_length['title_length'].fillna(0).astype(int)\n",
    "                mean_title_length = int(df_title_length['title_length'].replace(0, np.nan).mean())\n",
    "                df_title_length.loc[df_title_length['title_length'] == 0, 'title_length'] = mean_title_length\n",
    "                title_length_min = df_title_length['title_length'].min()\n",
    "                title_length_max = df_title_length['title_length'].max()\n",
    "                df_title_length['title_length'] = (df_title_length['title_length'] - title_length_min) / (title_length_max - title_length_min)\n",
    "                df_features = pd.concat([df_features, df_title_length], axis=1)\n",
    "\n",
    "            elif feature_method == \"Year_of_release\":\n",
    "                year = df_items[C.LABEL_COL].str.extract(r'\\((\\d{4})\\)')[0].astype(float)\n",
    "                df_year = year.to_frame(name='year_of_release')\n",
    "                mean_year = df_year.replace(0, np.nan).mean().iloc[0]\n",
    "                df_year['year_of_release'] = df_year['year_of_release'].fillna(mean_year).astype(int)\n",
    "                year_min = df_year['year_of_release'].min()\n",
    "                year_max = df_year['year_of_release'].max()\n",
    "                df_year['year_of_release'] = (df_year['year_of_release'] - year_min) / (year_max - year_min)\n",
    "                df_features = pd.concat([df_features, df_year], axis=1)\n",
    "\n",
    "            elif feature_method == \"average_ratings\":\n",
    "                average_rating = df_ratings.groupby('movieId')[C.RATING_COL].mean().rename('average_rating').to_frame()\n",
    "                global_avg = df_ratings[C.RATING_COL].mean()\n",
    "                average_rating['average_rating'] = average_rating['average_rating'].fillna(global_avg)\n",
    "                avg_rating_min = average_rating['average_rating'].min()\n",
    "                avg_rating_max = average_rating['average_rating'].max()\n",
    "                average_rating['average_rating'] = (average_rating['average_rating'] - avg_rating_min) / (avg_rating_max - avg_rating_min)\n",
    "                df_features = df_features.join(average_rating, how='left')\n",
    "\n",
    "            elif feature_method == \"count_ratings\":\n",
    "                rating_count = df_ratings.groupby('movieId')[C.RATING_COL].size().rename('rating_count').to_frame()\n",
    "                rating_count['rating_count'] = rating_count['rating_count'].fillna(0).astype(int)\n",
    "                mean_rating_count = int(rating_count['rating_count'].replace(0, np.nan).mean())\n",
    "                rating_count.loc[rating_count['rating_count'] == 0, 'rating_count'] = mean_rating_count\n",
    "                rating_count_min = rating_count['rating_count'].min()\n",
    "                rating_count_max = rating_count['rating_count'].max()\n",
    "                rating_count['rating_count'] = (rating_count['rating_count'] - rating_count_min) / (rating_count_max - rating_count_min)\n",
    "                df_features = df_features.join(rating_count, how='left')\n",
    "\n",
    "            elif feature_method == \"Genre_binary\":\n",
    "                df_genre_list = df_items[C.GENRES_COL].str.split('|').explode().to_frame('genre_list')\n",
    "                df_dummies = pd.get_dummies(df_genre_list['genre_list'])\n",
    "                df_genres = df_dummies.groupby(df_genre_list.index).sum()\n",
    "                df_genres = df_genres.reindex(df_items.index).fillna(0).astype(int)\n",
    "                df_features = pd.concat([df_features, df_genres], axis=1)\n",
    "\n",
    "            elif feature_method == \"Genre_tfidf\":\n",
    "                df_items['genre_string'] = df_items[C.GENRES_COL].fillna('').str.replace('|', ' ')\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_items['genre_string'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_items.index, columns=tfidf.get_feature_names_out())\n",
    "                df_features = pd.concat([df_features, tfidf_df], axis=1)\n",
    "\n",
    "            elif feature_method == \"Tags\":\n",
    "                tags_path = str(C.CONTENT_PATH / \"tags.csv\")\n",
    "                df_tags = pd.read_csv(tags_path)\n",
    "                df_tags = df_tags.dropna(subset=['tag'])\n",
    "                df_tags['tag'] = df_tags['tag'].astype(str)\n",
    "                df_tags_grouped = df_tags.groupby('movieId')['tag'].agg(' '.join).to_frame('tags')\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_tags_grouped['tags'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_tags_grouped.index, columns=tfidf.get_feature_names_out())\n",
    "                df_features = pd.concat([df_features, tfidf_df], axis=1)\n",
    "\n",
    "            elif feature_method == \"tmdb_vote_average\":\n",
    "                tmdb_path = str(C.CONTENT_PATH / \"tmdb_full_features.csv\")\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'vote_average']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_vote = df_tmdb['vote_average'].mean()\n",
    "                df_tmdb['vote_average'] = df_tmdb['vote_average'].fillna(mean_vote)\n",
    "                min_vote = df_tmdb['vote_average'].min()\n",
    "                max_vote = df_tmdb['vote_average'].max()\n",
    "                df_tmdb['vote_average'] = (df_tmdb['vote_average'] - min_vote) / (max_vote - min_vote)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "                    \n",
    "            elif feature_method == \"title_tfidf\":\n",
    "                # Combine titles into a single string per item\n",
    "                df_items['title_string'] = df_items[C.LABEL_COL].fillna('')\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_items['title_string'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_items.index, columns=tfidf.get_feature_names_out())\n",
    "                nltk.download('stopwords')\n",
    "                nltk.download('wordnet')\n",
    "                nltk.download('omw-1.4')\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                # Preprocess titles: remove stopwords and apply lemmatization\n",
    "                df_items['title_string'] = df_items[C.LABEL_COL].fillna('').apply(lambda x: ' '.join(\n",
    "                        lemmatizer.lemmatize(word) for word in x.split() if word.lower() not in stop_words\n",
    "                    )\n",
    "                )\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_items['title_string'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_items.index, columns=tfidf.get_feature_names_out())\n",
    "                df_features = pd.concat([df_features, tfidf_df], axis=1)\n",
    "       \n",
    "            elif feature_method == \"genome_tags\":\n",
    "                tags_path = C.CONTENT_PATH / \"genome-tags.csv\"\n",
    "                scores_path = C.CONTENT_PATH / \"genome-scores.csv\"\n",
    "                df_scores = pd.read_csv(scores_path)\n",
    "                df_tags = pd.read_csv(tags_path)\n",
    "                 # Étape 2 : Merge pour récupérer les noms des tags\n",
    "                df_merged = df_scores.merge(df_tags, on='tagId')\n",
    "                # Étape 3 : Pivot → films × tags, valeurs = relevance\n",
    "                df_features = df_merged.pivot_table(index='movieId', columns='tag', values='relevance', fill_value=0)\n",
    "        \n",
    "            elif feature_method == \"tfidf_relevance\":\n",
    "                tags_path = C.CONTENT_PATH / \"genome-tags.csv\"\n",
    "                scores_path = C.CONTENT_PATH / \"genome-scores.csv\"\n",
    "                # Charger les données\n",
    "                df_tags = pd.read_csv(tags_path)\n",
    "                df_scores = pd.read_csv(scores_path)\n",
    "                # Fusionner pour obtenir les noms des tags\n",
    "                df_merged = df_scores.merge(df_tags, on='tagId')\n",
    "                # Grouper les tags pertinents par film en texte\n",
    "                df_merged['tag'] = df_merged['tag'].astype(str)\n",
    "                df_texts = df_merged.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).to_frame('tags')\n",
    "                # Appliquer TF-IDF\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_texts['tags'])\n",
    "                # Créer le DataFrame final de features\n",
    "                df_features = pd.DataFrame(tfidf_matrix.toarray(), index=df_texts.index, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "            elif feature_method == \"tmdb_popularity\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'popularity']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_popularity = df_tmdb['popularity'].mean()\n",
    "                df_tmdb['popularity'] = df_tmdb['popularity'].fillna(mean_popularity)\n",
    "                min_popularity = df_tmdb['popularity'].min()\n",
    "                max_popularity = df_tmdb['popularity'].max()\n",
    "                df_tmdb['popularity'] = (df_tmdb['popularity'] - min_popularity) / (max_popularity - min_popularity)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "\n",
    "            elif feature_method == \"tmdb_budget\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'budget']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_budget = df_tmdb['budget'].mean()\n",
    "                df_tmdb['budget'] = df_tmdb['budget'].fillna(mean_budget)\n",
    "                min_budget = df_tmdb['budget'].min()\n",
    "                max_budget = df_tmdb['budget'].max()\n",
    "                df_tmdb['budget'] = (df_tmdb['budget'] - min_budget) / (max_budget - min_budget)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "            \n",
    "            elif feature_method == \"tmdb_revenue\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'revenue']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_revenue = df_tmdb['revenue'].mean()\n",
    "                df_tmdb['revenue'] = df_tmdb['revenue'].fillna(mean_revenue)\n",
    "                min_revenue = df_tmdb['revenue'].min()\n",
    "                max_revenue = df_tmdb['revenue'].max()\n",
    "                df_tmdb['revenue'] = (df_tmdb['revenue'] - min_revenue) / (max_revenue - min_revenue)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "            \n",
    "            elif feature_method == \"tmdb_profit\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb['profit'] = df_tmdb['revenue'] - df_tmdb['budget']\n",
    "                df_tmdb = df_tmdb[['movieId', 'profit']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_profit = df_tmdb['profit'].mean()\n",
    "                df_tmdb['profit'] = df_tmdb['profit'].fillna(mean_profit)\n",
    "                min_profit = df_tmdb['profit'].min()\n",
    "                max_profit = df_tmdb['profit'].max()\n",
    "                df_tmdb['profit'] = (df_tmdb['profit'] - min_profit) / (max_profit - min_profit)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "            \n",
    "            elif feature_method == \"tmdb_runtime\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'runtime']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_runtime = df_tmdb['runtime'].mean()\n",
    "                df_tmdb['runtime'] = df_tmdb['runtime'].fillna(mean_runtime)\n",
    "                min_runtime = df_tmdb['runtime'].min()\n",
    "                max_runtime = df_tmdb['runtime'].max()\n",
    "                df_tmdb['runtime'] = (df_tmdb['runtime'] - min_runtime) / (max_runtime - min_runtime)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "            \n",
    "            elif feature_method == \"tmdb_vote_count\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'vote_count']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                mean_vote_count = df_tmdb['vote_count'].mean()\n",
    "                df_tmdb['vote_count'] = df_tmdb['vote_count'].fillna(mean_vote_count)\n",
    "                min_vote_count = df_tmdb['vote_count'].min()\n",
    "                max_vote_count = df_tmdb['vote_count'].max()\n",
    "                df_tmdb['vote_count'] = (df_tmdb['vote_count'] - min_vote_count) / (max_vote_count - min_vote_count)\n",
    "                df_features = df_features.join(df_tmdb, how='left')\n",
    "            \n",
    "            elif feature_method == \"tmdb_cast\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'cast']].drop_duplicates('movieId')\n",
    "                df_tmdb['cast'] = df_tmdb['cast'].fillna('')\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_tmdb['cast'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_tmdb['movieId'], columns=tfidf.get_feature_names_out())\n",
    "                df_features = pd.concat([df_features, tfidf_df], axis=1)\n",
    "            \n",
    "            elif feature_method == \"tmdb_director\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'director']].drop_duplicates('movieId')\n",
    "                df_tmdb['director'] = df_tmdb['director'].fillna('')\n",
    "                tfidf = TfidfVectorizer()\n",
    "                tfidf_matrix = tfidf.fit_transform(df_tmdb['director'])\n",
    "                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_tmdb['movieId'], columns=tfidf.get_feature_names_out())\n",
    "                df_features = pd.concat([df_features, tfidf_df], axis=1)\n",
    "\n",
    "            elif feature_method == \"tmdb_original_language\":\n",
    "                tmdb_path = C.CONTENT_PATH / \"tmdb_full_features.csv\"\n",
    "                df_tmdb = pd.read_csv(tmdb_path)\n",
    "                df_tmdb = df_tmdb[['movieId', 'original_language']].drop_duplicates('movieId')\n",
    "                df_tmdb = df_tmdb.set_index('movieId')\n",
    "                df_tmdb['original_language'] = df_tmdb['original_language'].fillna('unknown')\n",
    "                # One-hot encoding des langues\n",
    "                df_lang_dummies = pd.get_dummies(df_tmdb['original_language'], prefix='lang')\n",
    "                # Gérer les valeurs manquantes après le merge\n",
    "                df_lang_dummies = df_lang_dummies.reindex(df_features.index, fill_value=0)\n",
    "                df_features = pd.concat([df_features, df_lang_dummies], axis=1) \n",
    "\n",
    "            \n",
    "            else:\n",
    "                raise NotImplementedError(f'Feature method {feature_method} not yet implemented')\n",
    "        return df_features\n",
    "    \n",
    "\n",
    "    def fit(self, trainset):\n",
    "        \"\"\"Profile Learner\"\"\"\n",
    "        self.content_features = self.create_content_features(self.features_method)\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        self.user_profile = {u: None for u in trainset.all_users()}\n",
    "        for u in self.user_profile:\n",
    "            user_items = trainset.ur[u]\n",
    "            if len(user_items) > 0:\n",
    "                # Sépare les item_ids internes et les notes\n",
    "                user_ratings = self.trainset.ur[u]\n",
    "                df_user = pd.DataFrame(user_ratings, columns=['inner_item_id', 'user_ratings'])\n",
    "                # Conversion des item_id internes (Surprise) en item_id \"raw\" (MovieLens)\n",
    "                df_user[\"item_id\"] = df_user[\"inner_item_id\"].map(self.trainset.to_raw_iid)\n",
    "                # Fusion avec les features de contenu (sur l'index = item_id raw)\n",
    "                df_user = df_user.merge(self.content_features, how='left', left_on='item_id', right_index=True)\n",
    "                # Préparation des features et des cibles pour l'entraînement\n",
    "                feature_names = list(self.content_features.columns)\n",
    "                X = df_user[feature_names].values\n",
    "                y = df_user['user_ratings'].values\n",
    "                # Gère les NaNs dans les features\n",
    "                X = np.nan_to_num(X)\n",
    "\n",
    "     \n",
    "                if self.regressor_method == 'linear': # Use linear regression\n",
    "                    model = LinearRegression(fit_intercept=True)\n",
    "                elif self.regressor_method == 'lasso':\n",
    "                    model = Lasso(alpha=0.1)\n",
    "                elif self.regressor_method == 'random_forest':\n",
    "                    model = RandomForestRegressor(n_estimators=10, max_depth=10, random_state=42)\n",
    "                elif self.regressor_method== 'neural_network':\n",
    "                    model = MLPRegressor(hidden_layer_sizes=(60, 60), max_iter=2500, learning_rate_init=0.01, alpha=0.0001, random_state=42)\n",
    "                elif self.regressor_method == 'decision_tree':\n",
    "                    model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "                elif self.regressor_method == 'ridge':\n",
    "                    model = Ridge(alpha=1.0)\n",
    "                elif self.regressor_method == 'gradient_boosting':\n",
    "                    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "                elif  self.regressor_method == 'knn':\n",
    "                    model = KNeighborsRegressor(n_neighbors=5)\n",
    "                elif self.regressor_method == 'elastic_net':\n",
    "                    model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "                else:\n",
    "                    self.user_profile[u] = None\n",
    "                    \n",
    "                model.fit(X, y)\n",
    "                self.user_profile[u] = model\n",
    "\n",
    "            else:\n",
    "             self.user_profile[u] = None\n",
    "             \n",
    "        \n",
    "    def estimate(self, u, i):\n",
    "        \"\"\"Scoring component used for item filtering\"\"\"\n",
    "        # First, handle cases for unknown users and items\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "\n",
    "        if self.user_profile[u] is None:\n",
    "            return self.trainset.global_mean\n",
    "\n",
    "        raw_item_id = self.trainset.to_raw_iid(i)\n",
    "        if raw_item_id in self.content_features.index:\n",
    "            item_features = self.content_features.loc[raw_item_id].values.reshape(1, -1)\n",
    "        else:\n",
    "            return self.trainset.global_mean\n",
    "    \n",
    "        if self.regressor_method == 'linear':\n",
    "            score = self.user_profile[u].predict(item_features)[0]\n",
    "        elif self.regressor_method in [\n",
    "        'linear',\n",
    "        'lasso',\n",
    "        'random_forest',\n",
    "        'neural_network',\n",
    "        'decision_tree',\n",
    "        'ridge',\n",
    "        'gradient_boosting',\n",
    "        'knn',\n",
    "        'elastic_net' ]:\n",
    "          score = self.user_profile[u].predict(item_features)[0]\n",
    "\n",
    "        else:\n",
    "            score=None\n",
    "            \n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd75b7e",
   "metadata": {},
   "source": [
    "The following script test the ContentBased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d12f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_contentbased_class(feature_method, regressor_method):\n",
    "    \"\"\"Test the ContentBased class.\n",
    "    Tries to make a prediction on the first (user,item ) tuple of the anti_test_set\n",
    "    \"\"\"\n",
    "    sp_ratings = load_ratings(surprise_format=True)\n",
    "    train_set = sp_ratings.build_full_trainset()\n",
    "    content_algo = ContentBased(feature_method, regressor_method)\n",
    "    content_algo.fit(train_set)\n",
    "    anti_test_set_first = train_set.build_anti_testset()[0]\n",
    "    prediction = content_algo.predict(anti_test_set_first[0], anti_test_set_first[1])\n",
    "    print(prediction)\n",
    "\n",
    "# (call here the test functions with different regressor methods)\n",
    "\n",
    "# Test 1 : prédiction aléatoire entre 0.5 et 5\n",
    "#test_contentbased_class(feature_method=None, regressor_method='random_score')\n",
    "\n",
    "# Test 2 : prédiction aléatoire parmi les notes données par l'utilisateur\n",
    "#test_contentbased_class(feature_method=None, regressor_method='random_sample')\n",
    "\n",
    "test_contentbased_class('tmdb_original_language','linear')\n",
    "test_contentbased_class('tmdb_runtime','linear')\n",
    "test_contentbased_class('tmdb_vote_count','linear')\n",
    "test_contentbased_class('tmdb_director','linear')\n",
    "test_contentbased_class('tmdb_cast','linear')\n",
    "test_contentbased_class('tmdb_revenue','linear')\n",
    "test_contentbased_class('tmdb_profit','linear')\n",
    "test_contentbased_class('tmdb_budget','linear')\n",
    "test_contentbased_class('tmdb_popularity','linear')\n",
    "test_contentbased_class('title_length','linear')\n",
    "test_contentbased_class('title_length','lasso')\n",
    "test_contentbased_class('title_length','random_forest')\n",
    "test_contentbased_class('title_length','neural_network')\n",
    "test_contentbased_class('title_length','decision_tree')\n",
    "test_contentbased_class('title_length','ridge')\n",
    "test_contentbased_class('title_length','gradient_boosting')\n",
    "test_contentbased_class('title_length','knn')\n",
    "test_contentbased_class('title_length','elastic_net')\n",
    "test_contentbased_class('Tags','linear')\n",
    "test_contentbased_class('Genre_tfidf','linear')\n",
    "test_contentbased_class('Genre_binary','linear')\n",
    "test_contentbased_class('title_length','linear')\n",
    "test_contentbased_class('Year_of_release','linear')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
