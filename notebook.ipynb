{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331a0e1f",
   "metadata": {},
   "source": [
    "## Recommender System - Guide du code et rappel th√©orique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05004e7e",
   "metadata": {},
   "source": [
    "### Structure et ordre d'utilisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b188a1",
   "metadata": {},
   "source": [
    "**Mapping**\n",
    "unzip.py renvoie les datas\n",
    "constants.py renvoie vers loaders.py\n",
    "\n",
    "loaders.py renvoie vers coding1.py, userbased.ipynb, contentbased.ipynb, models.py\n",
    "\n",
    "models.py renvoie vers evaluators.ipynb, hackaton_make_predictions.ipynb, configs.py\n",
    "\n",
    "configs.py renvoie vers evaluators.ipynb\n",
    "\n",
    "user_based.ipynb et content_based.ipynb permettent de comprendre la structure des 2 mod√®les, mais ceux-ci sont doubl√©s et utilit√©s √† partir de models.py\n",
    "\n",
    "\n",
    "**Workflow**\n",
    "1. Configurer les param√®tres souhait√©s dans Configs.py\n",
    "2. Run chaque block dans Evaluations.ipynb dans l'ordre\n",
    "3. Analyser les resultats obtenus dans mlsmm2156/data/small/evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a3058",
   "metadata": {},
   "source": [
    "### Description des fichiers et leurs fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c5137",
   "metadata": {},
   "source": [
    "#### constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666b7a8",
   "metadata": {},
   "source": [
    "Ce code d√©finit une classe de constantes Constant qui centralise tous les chemins d'acc√®s et noms de colonnes utilis√©s pour manipuler les donn√©es. L'objectif est d'automatiser et d'uniformiser les notations pour tous les fichiers.\n",
    "\n",
    "Cela comprend les chemins vers les fichiers de contenus (movies.csv), d'√©vidences (ratings.csv), les noms des colonnes importantes (comme userId, movieId, rating), ainsi que l'√©chelle des notes (de 1 √† 5). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d895dc4",
   "metadata": {},
   "source": [
    "#### loaders.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50b639",
   "metadata": {},
   "source": [
    "Ce code sert √† charger les donn√©es. \n",
    "\n",
    "**load_ratings** et **load_movies** : charger les ratings et les movies sous forme de dataframe \n",
    "Si surprise_format=True, elle convertit les donn√©es au format requis par la biblioth√®que Surprise, qui est utilis√©e pour impl√©menter et √©valuer des algorithmes de recommandation collaboratifs.\n",
    "Sinon, elle retourne simplement le fichier des ratings sous forme de DataFrame pandas classique, ce qui est utile pour l'exploration, le pr√©traitement ou l‚Äôanalyse descriptive.\n",
    "\n",
    "**export_evaluation_report** : permet d‚Äôenregistrer les r√©sultats d‚Äôune √©valuation (sous forme de DataFrame) dans un fichier CSV, avec un nom bas√© sur la date du jour pour √©viter d‚Äô√©craser les anciens rapports. Le fichier est sauvegard√© dans le dossier d√©fini par C.EVALUATION_PATH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999cede",
   "metadata": {},
   "source": [
    "#### coding1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e48f9d",
   "metadata": {},
   "source": [
    "Ce code effectue l'analyse exploratoire des donn√©es de notation dans un syst√®me de recommandation. Il commence par charger les jeux de donn√©es (notes et films), puis calcule des statistiques descriptives essentielles : nombre de notes, d'utilisateurs, de films, fr√©quence minimale et maximale de notation par film, valeurs de notes possibles, et nombre de films jamais not√©s. Ensuite, il visualise la distribution des notations par film pour mettre en √©vidence la \"long-tail property\", caract√©ristique fr√©quente dans les syst√®mes de recommandation (peu de films tr√®s populaires, beaucoup peu not√©s). Enfin, il construit une matrice creuse (sparse matrix) des interactions utilisateur-film, utile pour les algorithmes collaboratifs, et en calcule la sparsit√©, c‚Äôest-√†-dire le taux d'absences d‚Äôinteractions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8e8ac",
   "metadata": {},
   "source": [
    "#### models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4949f9c",
   "metadata": {},
   "source": [
    "L‚Äôid√©e de ce fichier est de combiner plusieurs strat√©gies pour estimer la pr√©f√©rence d‚Äôun utilisateur pour un item donn√©, et de produire des recommandations adapt√©es. Ce fichier inclut √† la fois des mod√®les simples servant de r√©f√©rences, des algorithmes classiques comme la factorisation matricielle (SVD), ainsi qu‚Äôun mod√®le content-based qui exploite des caract√©ristiques d√©taill√©es des items et des m√©thodes d‚Äôapprentissage supervis√© pour pr√©dire les notes.\n",
    "\n",
    "**get_top_n** : cette fonction transforme une liste brute de pr√©dictions en une liste organis√©e des meilleures recommandations pour chaque utilisateur. Elle prend en entr√©e un ensemble de pr√©dictions (notes estim√©es par un mod√®le pour chaque couple utilisateur-item) et retourne pour chaque utilisateur une liste des items les mieux not√©s selon ces pr√©dictions, limit√©e √† un nombre n choisi. Pour √©viter que des pr√©dictions √† valeur identique se retrouvent toujours dans le m√™me ordre, la fonction introduit un m√©lange al√©atoire avant de trier par ordre d√©croissant, ce qui permet d‚Äôavoir un comportement plus √©quitable. Ce m√©canisme est utile pour obtenir une liste finale qui pourra √™tre pr√©sent√©e √† l‚Äôutilisateur.\n",
    "\n",
    "**ModelBaseline1** : cette classe pr√©dit toujours la m√™me note fixe (2) pour tous les utilisateurs et items, servant de r√©f√©rence simple\n",
    "\n",
    "**ModelBaseline2** : cette classe g√©n√®re des pr√©dictions al√©atoires dans la plage des notes possibles, pour simuler un mod√®le sans apprentissage\n",
    "\n",
    "**ModelBaseline3** : cette classe pr√©dit la moyenne globale des notes observ√©es, ce qui refl√®te une tendance g√©n√©rale sans personnalisation\n",
    "\n",
    "**ModelBaseline4(SVD)** : impl√©mentation d‚Äôun algorithme plus avanc√©, bas√©e sur la factorisation matricielle dite SVD. Cette m√©thode cherche √† repr√©senter chaque utilisateur et chaque item dans un espace latent de faible dimension, de mani√®re √† mod√©liser les interactions sous-jacentes qui expliquent les √©valuations. Lors de l‚Äôentra√Ænement, ce mod√®le apprend ces repr√©sentations latentes √† partir du jeu de donn√©es. Sa m√©thode estimate utilise ces repr√©sentations pour pr√©dire la note qu‚Äôun utilisateur donnerait √† un item, en calculant un produit scalaire pond√©r√© des vecteurs latents.\n",
    "\n",
    "**ContentBased** : copie du mod√®le dans le fichier content_based.ipynb -> voir explications l√†-bas\n",
    "\n",
    "**UserBased** : copie du mod√®le dans le fichier user_based.ipynb -> voir explications l√†-bas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fdd85",
   "metadata": {},
   "source": [
    "#### user_based.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ddd8b",
   "metadata": {},
   "source": [
    "//1.Loading Data//\n",
    "Chargement des donn√©es, cr√©ation du trainset et de l'antitest-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492f83c",
   "metadata": {},
   "source": [
    "//2. Explore Surprise's user based algorithm//\n",
    "Ce code met en ≈ìuvre un algorithme user-user avec moyennes centr√©es (KNNWithMeans) √† l‚Äôaide de la biblioth√®que Surprise. Il permet de visualiser les r√©sultats du mod√®le via une m√©trique choisie et d'analyser les variations des hyperparam√®tres.\n",
    "\n",
    "Voici les √©tapes cl√©s :\n",
    "    Le mod√®le est entra√Æn√© sur l‚Äôensemble d‚Äôentra√Ænement trainset.\n",
    "    Une pr√©diction est ensuite effectu√©e pour l'utilisateur 11 et le film 364, illustrant l‚Äôutilisation du mod√®le pour une recommandation sp√©cifique.\n",
    "    Une pr√©diction de masse est ensuite g√©n√©r√©e sur l'anti-test set (toutes les paires utilisateur-film inconnues), et les 30 premi√®res sont affich√©es avec la note estim√©e.\n",
    "    Enfin, la matrice de similarit√© utilisateur-utilisateur est partiellement affich√©e pour visualiser comment les utilisateurs sont corr√©l√©s entre eux selon l‚Äôalgorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc810f55",
   "metadata": {},
   "source": [
    "//3. Implement and explore a customizable user-based algorithm//\n",
    "Algorithme de Surprise. Le mod√®le apprend donc une matrice de similarit√© entre utilisateurs, puis pr√©dit les notes d‚Äôun utilisateur pour un film en agissant comme une moyenne pond√©r√©e des notes donn√©es √† ce film par les utilisateurs similaires\n",
    "\n",
    "**__init__(self, k=3, min_k=1, sim_options={}, kwargs)** : permet d'initialiser les param√®tres \n",
    "\n",
    "**fit(self, trainset)** : Cette m√©thode pr√©pare tout ce dont le mod√®le a besoin pour fonctionner : \n",
    "il stocke le trainset fourni par Surprise \n",
    "puis construit la matrice utilisateur-film ratings_matrix avec des NaN pour les absences de notes\n",
    "puis calcule la matrice de similarit√© entre utilisateurs selon la m√©thode choisie (msd, jaccard, etc.)\n",
    "puis calcule les moyennes des notes donn√©es par chaque utilisateur (utile comme base de pr√©diction par d√©faut ou de correction)\n",
    "\n",
    "**estimate(self, u, i)** : Cette m√©thode pr√©dit la note que l'utilisateur u pourrait donner √† l‚Äôitem (film) i :\n",
    "Si l‚Äôutilisateur ou le film est inconnu, retourne NaN.\n",
    "Utilise la moyenne des notes de l'utilisateur u comme pr√©diction de base.\n",
    "Cherche tous les autres utilisateurs ayant not√© l‚Äôitem i.\n",
    "Calcule la diff√©rence entre leur note et leur propre moyenne, pond√©r√©e par leur similarit√© avec u.\n",
    "Prend les k utilisateurs les plus similaires, et combine leur contribution pour ajuster la pr√©diction.\n",
    "Si le nombre de voisins valides est sup√©rieur √† min_k, la pr√©diction est retourn√©e ; sinon on garde la moyenne de u.\n",
    "\n",
    "**compute_ratings_matrix(self)** : Cr√©e une matrice dense ratings_matrix, de taille (n_users, n_items), initialis√©e √† NaN. Elle est remplie avec les notes connues du trainset. Elle est utilis√©e pour comparer les utilisateurs entre eux\n",
    "\n",
    "**compute_similarity_matrix(self)** : Construit la matrice de similarit√© sym√©trique entre utilisateurs :\n",
    "Si la m√©thode est msd (Mean Squared Difference) : compare les notes communes des utilisateurset applique la formule sim = 1 / (1 + MSD) si le support est suffisant.\n",
    "Si la m√©thode est jaccard : calcule la similarit√© entre les ensembles de films not√©s (ind√©pendamment des valeurs de note).\n",
    "\n",
    "Le r√©sultat est une matrice carr√©e sim de taille (n_users, n_users).\n",
    "\n",
    "**jaccard_similarity(self, row_i, row_j)** : Cette fonction calcule la similarit√© de Jaccard entre deux utilisateurs en se basant uniquement sur les films qu‚Äôils ont not√©s (et non sur la note elle-m√™me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58420a",
   "metadata": {},
   "source": [
    "//4. Compare KNNWithMeans with UserBased//\n",
    "\n",
    "Ce code compare les pr√©dictions du mod√®le UserBased impl√©ment√© manuellement √† celles du mod√®le KNNWithMeans de Surprise, en utilisant les m√™mes param√®tres de similarit√© (msd, k=3, min_k=2). L‚Äôobjectif est de valider que les deux algorithmes produisent des r√©sultats coh√©rents, ce qui permet de v√©rifier la justesse de l‚Äôimpl√©mentation personnalis√©e du UserBased. Cela sert donc de test d‚Äô√©quivalence entre une version maison et une version de r√©f√©rence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d8db1",
   "metadata": {},
   "source": [
    "//5. Compare MSD and Jaccard//\n",
    "\n",
    "Ce code compare simplement les pr√©dictions faites par la similarit√© MSD et la similarit√© Jaccard, tout deux plac√© dans le mod√®le UserBased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceed114",
   "metadata": {},
   "source": [
    "#### content_based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa7f08",
   "metadata": {},
   "source": [
    "//Explore and select content features//\n",
    "\n",
    "Ce bloc de code sert √† extraire et construire des caract√©ristiques (features) descriptives √† partir des donn√©es de films pour enrichir le mod√®le de recommandation. Il est utilis√© pour de la recherche mais pas forc√©ment utile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9dc60",
   "metadata": {},
   "source": [
    "//Build a Content Based Model//\n",
    "\n",
    "**class ContentBased**\n",
    "Ce mod√®le de recommandation bas√© sur le contenu apprend une fonction de notation personnalis√©e pour chaque utilisateur. Il transforme d'abord chaque film en un vecteur de caract√©ristiques (features) descriptives, puis, pour chaque utilisateur, il entra√Æne un mod√®le de r√©gression distinct qui apprend √† pr√©dire les notes de cet utilisateur en se basant sur les caract√©ristiques des films qu'il a d√©j√† √©valu√©s.\n",
    "\n",
    "**__init__(self, features_method, regressor_method)** : C'est le constructeur de la classe. Il initialise l'algorithme en stockant les m√©thodes choisies pour l'extraction des caract√©ristiques (features_method) et pour le mod√®le de r√©gression (regressor_method). Il appelle √©galement create_content_features une premi√®re fois pour g√©n√©rer le DataFrame global des caract√©ristiques des items (films), qui sera utilis√© par tous les utilisateurs.\n",
    "\n",
    "**create_content_features(self, features_methods)** : Cette fonction est le \"Content Analyzer\". Elle charge les informations sur les items (films) et, en fonction des features_methods sp√©cifi√©s (ex: \"title_length\", \"Genre_binary\", \"Tags\" avec TF-IDF), elle construit un DataFrame o√π chaque ligne correspond √† un film et chaque colonne √† une caract√©ristique extraite et pr√©trait√©e (souvent normalis√©e).\n",
    "\n",
    "**fit(self, trainset)** : C'est le \"Profile Learner\". Cette m√©thode entra√Æne le mod√®le.\n",
    "\n",
    "    Elle s'assure d'abord que les content_features sont √† jour (en les recalculant si n√©cessaire, bien que dans votre code actuel, elles soient d√©j√† calcul√©es dans __init__).\n",
    "    Elle initialise un dictionnaire user_profile pour stocker un mod√®le de r√©gression distinct pour chaque utilisateur.\n",
    "    Pour chaque utilisateur du trainset :\n",
    "        Elle r√©cup√®re les films que l'utilisateur a not√©s et leurs notes.\n",
    "        Elle associe ces films √† leurs caract√©ristiques (issues de self.content_features).\n",
    "        Elle utilise ces caract√©ristiques comme variables explicatives (X) et les notes de l'utilisateur comme variable cible (y).\n",
    "        Elle entra√Æne un mod√®le de r√©gression (sp√©cifi√© par self.regressor_method, ex: LinearRegression, RandomForestRegressor) sur ces donn√©es sp√©cifiques √† l'utilisateur.\n",
    "        Le mod√®le entra√Æn√© pour cet utilisateur est stock√© dans self.user_profile[u]. S'il n'y a pas assez de donn√©es ou si une m√©thode de r√©gression n'est pas sp√©cifi√©e, le profil peut rester None\n",
    "\n",
    "**estimate(self, u, i)** : C'est le \"Scoring Component\". Cette m√©thode pr√©dit la note qu'un utilisateur u donnerait √† un item (film) i. Elle v√©rifie d'abord si l'utilisateur et l'item sont connus dans le trainset. Si l'user est inconnu (cad si self.user_profile[u] est None, par exemple pour un utilisateur avec peu de notes), elle retourne la note moyenne globale du trainset. Elle r√©cup√®re les caract√©ristiques de l'item i √† partir de self.content_features. Si l'item n'a pas de caract√©ristiques (n'est pas dans l'index), elle retourne aussi la moyenne globale.\n",
    "Elle utilise le mod√®le de r√©gression personnel de l'utilisateur u (stock√© dans self.user_profile[u]) pour pr√©dire une note en se basant sur les caract√©ristiques de l'item i. Elle retourne cette note pr√©dite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efcc27",
   "metadata": {},
   "source": [
    "// Tester pour voir \n",
    "\n",
    "**test_contentbased_class** : Cette fonction test_contentbased_class permet de tester rapidement une impl√©mentation du mod√®le de recommandation bas√© sur le contenu (ContentBased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af4ed4",
   "metadata": {},
   "source": [
    "#### configs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c252499",
   "metadata": {},
   "source": [
    "Ce fichier agit comme une interface de configuration centralis√©e pour automatiser les exp√©riences. Il permet de changer les mod√®les, m√©thodes, ou param√®tres sans modifier le code principal d‚Äô√©valuation, ce qui rend le syst√®me modulaire et facilement extensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfae2b",
   "metadata": {},
   "source": [
    "#### evaluators.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60637980",
   "metadata": {},
   "source": [
    "\\\\1. Model Validation Functions//\n",
    "\n",
    "**load_ratings(surprise_format=False)** : \n",
    "Cette fonction charge le fichier de ratings (notes donn√©es par les utilisateurs aux films).\n",
    "Si surprise_format=True, elle formate les donn√©es pour qu‚Äôelles soient compatibles avec la biblioth√®que Surprise (utilis√©e pour entra√Æner les algorithmes de recommandation).\n",
    "Sinon, elle retourne simplement un DataFrame pandas brut.\n",
    "\n",
    "**generate_split_predictions(algo, ratings_dataset, eval_config)** : \n",
    "Cette fonction √©value un mod√®le √† l‚Äôaide d‚Äôun √©chantillonnage al√©atoire : elle divise les donn√©es en un ensemble d'entra√Ænement et un ensemble de test (selon test_size).\n",
    "Elle entra√Æne l‚Äôalgorithme (algo) sur les donn√©es d‚Äôentra√Ænement, puis pr√©dit les notes sur le testset.\n",
    "Les pr√©dictions obtenues sont ensuite utilis√©es pour calculer des m√©triques de pr√©cision comme MAE ou RMSE.\n",
    "\n",
    "**generate_loo_top_n(algo, ratings_dataset, eval_config)** : \n",
    "Cette fonction utilise la m√©thode du Leave-One-Out (LOO), qui consiste √† cacher une note par utilisateur pour tester la pertinence des recommandations.\n",
    "Apr√®s entra√Ænement sur les autres notes, l‚Äôalgorithme g√©n√®re des recommandations sur les films non vus.\n",
    "On extrait les top-N recommandations pour chaque utilisateur et on v√©rifie si l‚Äôitem retir√© en fait partie (ex. via le hit rate).\n",
    "\n",
    "**generate_full_top_n(algo, ratings_dataset, eval_config)** :\n",
    "Ici, l‚Äôalgorithme est entra√Æn√© sur la totalit√© des donn√©es disponibles.\n",
    "Il pr√©dit ensuite les notes sur tous les films que chaque utilisateur n‚Äôa jamais not√©s (anti-testset).\n",
    "On en extrait les top-N recommandations pour chaque utilisateur.\n",
    "Cette approche permet d‚Äô√©valuer la qualit√© globale des recommandations, notamment leur originalit√© (ex : avec la m√©trique novelty).\n",
    "\n",
    "**precompute_information()** : \n",
    "Cette fonction calcule des informations utiles pour certaines m√©triques d‚Äô√©valuation.\n",
    "Elle compte combien de fois chaque film a √©t√© not√©, puis classe les films par popularit√© d√©croissante.\n",
    "Elle cr√©e un dictionnaire item_to_rank qui associe √† chaque film son rang (1 = le plus populaire).\n",
    "Ce classement est ensuite utilis√© pour √©valuer la nouveaut√© des recommandations (pr√©f√©rer des films moins vus).\n",
    "\n",
    "**create_evaluation_report(eval_config, sp_ratings, precomputed_dict, available_metrics)** : \n",
    "C‚Äôest la fonction principale qui orchestre l‚Äô√©valuation de tous les mod√®les d√©finis dans EvalConfig.\n",
    "Elle applique successivement les trois types d‚Äô√©valuation (split, loo, full) et calcule les m√©triques correspondantes.\n",
    "Pour chaque mod√®le, elle entra√Æne l‚Äôalgorithme, g√©n√®re les pr√©dictions et appelle les fonctions d‚Äô√©valuation ad√©quates.\n",
    "Elle compile tous les r√©sultats dans un DataFrame r√©sum√©, pr√™t √† √™tre analys√© ou affich√© dans un rapport final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d3f68",
   "metadata": {},
   "source": [
    "\\\\2. Evaluation metrics//\n",
    "\n",
    "**get_hit_rate(anti_testset_top_n, testset)** : \n",
    "Cette fonction calcule le hit rate, elle v√©rifie, pour chaque utilisateur, si le film retir√© du jeu de donn√©es (et plac√© dans le testset) appara√Æt dans ses top-N recommandations (anti_testset_top_n).\n",
    "Un \"hit\" (succ√®s) vaut 1 si le film est retrouv√©, sinon c‚Äôest un \"fail\" (0).\n",
    "On calcule ensuite la proportion moyenne de succ√®s sur l‚Äôensemble des utilisateurs.\n",
    "C‚Äôest une mesure simple mais efficace pour √©valuer la capacit√© du syst√®me √† retrouver des films pertinents.\n",
    "\n",
    "**get_novelty(anti_testset_top_n, item_to_rank)** : \n",
    "Cette fonction mesure la nouveaut√© des recommandations en utilisant le rang de popularit√© des films.\n",
    "Plus un film recommand√© est impopulaire (rang √©lev√©), plus il est consid√©r√© comme \"novel\" (nouveau).\n",
    "Elle parcourt toutes les recommandations faites aux utilisateurs, additionne les rangs des films et calcule une moyenne.\n",
    "Cette moyenne est ensuite normalis√©e par le nombre total de films pour donner un score compris entre 0 et 1.\n",
    "Plus le score est √©lev√©, plus le syst√®me propose des contenus originaux et rarement vus par les autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64604840",
   "metadata": {},
   "source": [
    "\\\\3. Evaluation workflow//\n",
    "\n",
    "Ce bloc de code sert √† √©valuer un ou plusieurs mod√®les de recommandation d√©finis dans EvalConfig √† l‚Äôaide de diff√©rentes m√©triques. Il commence par charger les donn√©es de notation au format Surprise (sp_ratings) et initialise un dictionnaire vide pour les informations pr√©-calcul√©es (precomputed_dict). Ensuite, la fonction create_evaluation_report est appel√©e pour entra√Æner les mod√®les et calculer les performances selon les m√©triques d√©finies (comme MAE, RMSE, hit_rate, novelty). Enfin, les r√©sultats sont affich√©s √† l‚Äô√©cran puis export√©s gr√¢ce √† export_evaluation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec36e47",
   "metadata": {},
   "source": [
    "### üìê Metriques d'√©valuations rappel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0467d3e",
   "metadata": {},
   "source": [
    "üîπ 1. MAE (Mean Absolute Error) ‚Äì Erreur absolue moyenne\n",
    "\n",
    "    Objectif : mesurer la pr√©cision moyenne des pr√©dictions du syst√®me, en regardant √† quel point les pr√©dictions sont √©loign√©es des notes r√©elles.\n",
    "\n",
    "    Formule :\n",
    "    MAE=1N‚àëi=1N‚à£r^i‚àíri‚à£\n",
    "    MAE=N1‚Äãi=1‚àëN‚Äã‚à£r^i‚Äã‚àíri‚Äã‚à£\n",
    "\n",
    "    o√π :\n",
    "\n",
    "        r^ir^i‚Äã = note pr√©dite\n",
    "\n",
    "        riri‚Äã = note r√©elle\n",
    "\n",
    "        NN = nombre total de pr√©dictions\n",
    "\n",
    "    Interpr√©tation :\n",
    "\n",
    "        Plus MAE est proche de 0, plus les pr√©dictions sont pr√©cises.\n",
    "\n",
    "        Une MAE de 0.5 signifie que, en moyenne, les pr√©dictions sont √† 0.5 point d‚Äô√©cart des vraies notes.\n",
    "\n",
    "üîπ 2. RMSE (Root Mean Squared Error) ‚Äì Racine carr√©e de l'erreur quadratique moyenne\n",
    "\n",
    "    Objectif : mesurer la pr√©cision globale, mais en p√©nalisant davantage les grandes erreurs.\n",
    "\n",
    "    Formule :\n",
    "    RMSE=1N‚àëi=1N(r^i‚àíri)2\n",
    "    RMSE=N1‚Äãi=1‚àëN‚Äã(r^i‚Äã‚àíri‚Äã)2\n",
    "\n",
    "    ‚Äã\n",
    "\n",
    "    Diff√©rence avec MAE :\n",
    "\n",
    "        RMSE met plus de poids sur les grosses erreurs.\n",
    "\n",
    "        Exemple : une erreur de 2 compte plus fortement qu‚Äôune erreur de 1, car elle est au carr√©.\n",
    "\n",
    "üîπ 3. Hit Rate ‚Äì Taux de couverture de l‚Äôutilisateur\n",
    "\n",
    "    Objectif : mesurer si l‚Äô√©l√©ment que l‚Äôutilisateur a r√©ellement aim√© est pr√©sent dans les recommandations du syst√®me.\n",
    "\n",
    "    Utilis√© dans : Leave-One-Out (LOO)\n",
    "    On retire un item que l‚Äôutilisateur a not√©, puis on g√©n√®re des recommandations, et on regarde s‚Äôil est dedans.\n",
    "\n",
    "    Formule :\n",
    "    Hit Rate=Nombre de hitsNombre total de tests\n",
    "    Hit Rate=Nombre total de testsNombre de hits‚Äã\n",
    "\n",
    "    Exemple :\n",
    "    Si on fait √ßa pour 100 utilisateurs, et que dans 75 cas le syst√®me a recommand√© l‚Äôitem retir√© ‚Üí Hit Rate = 0.75.\n",
    "\n",
    "    Int√©r√™t :\n",
    "\n",
    "        C‚Äôest une m√©trique binaire : est-ce que l‚Äôitem \"test\" est dans le top-N recommandations ou non ?\n",
    "\n",
    "        Plus elle est √©lev√©e, mieux le syst√®me retrouve les go√ªts pass√©s des utilisateurs.\n",
    "\n",
    "üîπ 4. Novelty ‚Äì Nouveaut√©\n",
    "\n",
    "    Objectif : √©valuer si le syst√®me recommande des choses originales, peu connues, plut√¥t que toujours les m√™mes blockbusters.\n",
    "\n",
    "    Pourquoi c‚Äôest important ?\n",
    "    Un syst√®me qui recommande toujours les films les plus populaires est peu utile √† long terme. La \"nouveaut√©\" incite √† la diversit√© des d√©couvertes.\n",
    "\n",
    "    Comment c‚Äôest mesur√© ?\n",
    "    Souvent par :\n",
    "\n",
    "        Popularit√© inverse : plus un film est populaire, moins il est \"novel\".\n",
    "\n",
    "        Calcul bas√© sur le log du nombre de vues :\n",
    "        Novelty=1‚à£R‚à£‚àëi‚ààR‚àílog‚Å°2(p(i))\n",
    "        Novelty=‚à£R‚à£1‚Äãi‚ààR‚àë‚Äã‚àílog2‚Äã(p(i))\n",
    "\n",
    "        o√π p(i)p(i) est la probabilit√© d'apparition de l'item (fr√©quence), et RR l'ensemble des items recommand√©s.\n",
    "\n",
    "    Interpr√©tation :\n",
    "\n",
    "        Une valeur plus √©lev√©e = des recommandations moins connues, donc plus \"originales\"."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
