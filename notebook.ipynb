{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331a0e1f",
   "metadata": {},
   "source": [
    "## Recommender System - Guide du code et rappel théorique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05004e7e",
   "metadata": {},
   "source": [
    "### Structure et ordre d'utilisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b188a1",
   "metadata": {},
   "source": [
    "**Mapping**\n",
    "unzip.py renvoie les datas\n",
    "constants.py renvoie vers loaders.py\n",
    "\n",
    "loaders.py renvoie vers coding1.py, userbased.ipynb, contentbased.ipynb, models.py\n",
    "\n",
    "models.py renvoie vers evaluators.ipynb, hackaton_make_predictions.ipynb, configs.py\n",
    "\n",
    "configs.py renvoie vers evaluators.ipynb\n",
    "\n",
    "user_based.ipynb et content_based.ipynb permettent de comprendre la structure des 2 modèles, mais ceux-ci sont doublés et utilités à partir de models.py\n",
    "\n",
    "\n",
    "**Workflow**\n",
    "1. Configurer les paramètres souhaités dans Configs.py\n",
    "2. Run chaque block dans Evaluations.ipynb dans l'ordre\n",
    "3. Analyser les resultats obtenus dans mlsmm2156/data/small/evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68059c",
   "metadata": {},
   "source": [
    "Voici une description de chaque fichier Python de votre projet et de son rôle dans le système de recommandation de films :\n",
    "\n",
    "1. constants.py\n",
    "\n",
    "    Rôle : Centralise toutes les constantes globales utilisées à travers le projet.\n",
    "\n",
    "    Contenu typique :\n",
    "\n",
    "        Chemins vers les répertoires de données (DATA_PATH, CONTENT_PATH, EVIDENCE_PATH, EVALUATION_PATH).\n",
    "\n",
    "        Noms des fichiers de données (par exemple, ITEMS_FILENAME, RATINGS_FILENAME, TMDB_FILENAME, NEW_RATINGS_PENDING_FILENAME, USER_PROFILES_FILENAME).\n",
    "\n",
    "        Noms des colonnes dans les DataFrames (par exemple, ITEM_ID_COL, USER_ID_COL, RATING_COL, LABEL_COL, GENRES_COL).\n",
    "\n",
    "        Échelle des ratings (RATINGS_SCALE).\n",
    "\n",
    "    Interaction : Presque tous les autres fichiers (loaders.py, models.py, content.py, recommender.py, training.py, app.py, merge_new_ratings.py) importent et utilisent la classe Constant (ou une instance C) de ce fichier pour accéder à ces valeurs standardisées. Cela rend le code plus maintenable, car si un nom de colonne ou un chemin change, la modification ne doit être faite qu'à un seul endroit.\n",
    "\n",
    "2. loaders.py\n",
    "\n",
    "    Rôle : Responsable du chargement, du nettoyage initial et de la préparation des données brutes à partir des fichiers CSV.\n",
    "\n",
    "    Fonctionnalités clés :\n",
    "\n",
    "        load_items(): Charge movies.csv, tmdb_full_features.csv, et links.csv. Il fusionne ces informations pour créer un DataFrame df_items_global enrichi avec les attributs des films (titre, année, genres, informations TMDB comme la popularité, les notes moyennes TMDB, etc.). Il effectue un nettoyage important, notamment sur la colonne des genres pour standardiser le format.\n",
    "\n",
    "        load_ratings(): Charge ratings.csv pour créer df_ratings_global contenant les évaluations des utilisateurs.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise constants.py pour les chemins et les noms de colonnes.\n",
    "\n",
    "        Est appelé par models.py pour charger df_items_global et df_ratings_global qui sont ensuite utilisés globalement.\n",
    "\n",
    "        Est appelé directement par app.py au démarrage pour s'assurer que l'application dispose des données les plus récentes.\n",
    "\n",
    "3. models.py\n",
    "\n",
    "    Rôle : Définit les différentes classes d'algorithmes de recommandation et charge les données globales nécessaires à leur fonctionnement.\n",
    "\n",
    "    Contenu typique :\n",
    "\n",
    "        Chargement initial de df_items_global et df_ratings_global en utilisant loaders.py. Ces DataFrames sont ensuite disponibles pour les autres modules qui importent depuis models.py.\n",
    "\n",
    "        Définition des classes d'algorithmes de recommandation basées sur surprise.AlgoBase :\n",
    "\n",
    "            ContentBased: Implémente la logique de recommandation basée sur le contenu. Elle crée des features à partir des attributs des items (genres, année, tags, etc.) et entraîne un modèle de régression par utilisateur.\n",
    "\n",
    "            UserBased: Wrapper pour surprise.KNNWithMeans (approche collaborative basée sur les utilisateurs).\n",
    "\n",
    "            SVDAlgo: Wrapper pour surprise.SVD (approche collaborative basée sur la factorisation de matrices).\n",
    "\n",
    "            Potentiellement d'autres modèles (par exemple, ModelBaseline4 mentionné dans configs.py).\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise constants.py et loaders.py.\n",
    "\n",
    "        Fournit les DataFrames globaux (df_items_global, df_ratings_global) à content.py, recommender.py, et app.py.\n",
    "\n",
    "        Les classes de modèles sont utilisées par training.py pour entraîner les modèles et les sauvegarder.\n",
    "\n",
    "        Les modèles sauvegardés sont ensuite chargés par recommender.py pour faire des prédictions.\n",
    "\n",
    "4. content.py\n",
    "\n",
    "    Rôle : Fournit des fonctions utilitaires pour accéder facilement aux métadonnées des films (titre, genres, année, etc.) stockées dans df_items_global.\n",
    "\n",
    "    Fonctionnalités clés :\n",
    "\n",
    "        Fonctions comme get_movie_title(), get_movie_genres(), get_movie_release_year(), get_movie_tmdb_vote_average().\n",
    "\n",
    "        get_movie_details_list(): Récupère les détails pour une liste d'ID de films.\n",
    "\n",
    "        get_all_movies_for_selection(): Fournit une liste de films pour les formulaires de sélection.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Importe df_items_global depuis models.py (ou le charge directement si l'import échoue).\n",
    "\n",
    "        Utilise constants.py.\n",
    "\n",
    "        Est utilisé par app.py pour afficher les informations des films dans l'interface utilisateur.\n",
    "\n",
    "        Est utilisé par recommender.py pour enrichir les recommandations avec les détails des films.\n",
    "\n",
    "5. training.py\n",
    "\n",
    "    Rôle : Script hors ligne pour entraîner les différents modèles de recommandation (SVD, UserBased, ContentBased) sur l'ensemble des données d'évaluation et les sauvegarder sur disque.\n",
    "\n",
    "    Processus :\n",
    "\n",
    "        Charge les données d'évaluation (df_ratings_global via models.py ou directement le CSV pour surprise.Dataset).\n",
    "\n",
    "        Construit un trainset Surprise.\n",
    "\n",
    "        Instancie les modèles définis dans models.py.\n",
    "\n",
    "        Entraîne chaque modèle sur le trainset.\n",
    "\n",
    "        Sauvegarde les modèles entraînés (généralement des fichiers .p) dans le répertoire spécifié par C.DATA_PATH / 'recs'.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise constants.py, models.py (pour les classes d'algorithmes et df_ratings_global).\n",
    "\n",
    "        Utilise la bibliothèque surprise pour la manipulation des datasets et la sauvegarde des modèles (dump).\n",
    "\n",
    "        Ce script est exécuté manuellement (ou par une tâche planifiée) après la mise à jour du fichier principal des évaluations (par exemple, après l'exécution de merge_new_ratings.py).\n",
    "\n",
    "6. recommender.py\n",
    "\n",
    "    Rôle : Gère la logique de génération de recommandations pour un utilisateur donné en utilisant les modèles pré-entraînés.\n",
    "\n",
    "    Fonctionnalités clés :\n",
    "\n",
    "        load_model(): Charge un modèle sérialisé (fichier .p) depuis le disque. Met en cache les modèles chargés pour éviter les rechargements redondants.\n",
    "\n",
    "        get_movies_watched_by_user(): Récupère les films déjà vus par un utilisateur.\n",
    "\n",
    "        get_top_n_recommendations():\n",
    "\n",
    "            Charge le modèle spécifié.\n",
    "\n",
    "            Identifie les films candidats pour la recommandation (tous les films moins ceux déjà vus par l'utilisateur, si spécifié).\n",
    "\n",
    "            Applique des filtres optionnels (genre, année).\n",
    "\n",
    "            Prédit les scores pour les films candidats en utilisant le modèle chargé.\n",
    "\n",
    "            Trie les films par score prédit et retourne le top N.\n",
    "\n",
    "            Enrichit les recommandations avec les détails des films en utilisant content.py.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise constants.py, content.py.\n",
    "\n",
    "        Importe df_ratings_global depuis models.py (ou le charge) pour get_movies_watched_by_user.\n",
    "\n",
    "        Utilise surprise.dump pour charger les modèles.\n",
    "\n",
    "        Est intensivement utilisé par app.py pour obtenir et afficher les recommandations personnalisées.\n",
    "\n",
    "7. app.py\n",
    "\n",
    "    Rôle : Constitue l'interface utilisateur web de l'application, construite avec Streamlit. C'est le point d'entrée principal pour l'interaction utilisateur.\n",
    "\n",
    "    Fonctionnalités clés :\n",
    "\n",
    "        Navigation : Permet de naviguer entre différentes sections (Tops Généraux, Recommandations Personnalisées, Création de Profil).\n",
    "\n",
    "        Affichage des Tops : Affiche les films les mieux notés globalement ou par genre, avec filtres (année, genre).\n",
    "\n",
    "        Création de Profil Utilisateur :\n",
    "\n",
    "            Permet à un nouvel utilisateur de saisir son nom.\n",
    "\n",
    "            Présente une sélection de films à noter.\n",
    "\n",
    "            Sauvegarde le nom et les évaluations de l'utilisateur dans des fichiers CSV temporaires (new_ratings_pending.csv, user_profiles.csv) pour un traitement hors ligne.\n",
    "\n",
    "        Recommandations Personnalisées (Utilisateurs Existants) :\n",
    "\n",
    "            Permet à un utilisateur de sélectionner son profil (ID) dans une liste.\n",
    "\n",
    "            Permet de choisir les types de modèles à utiliser pour les recommandations (User-based, Content-based, SVD).\n",
    "\n",
    "            Appelle recommender.py pour obtenir les recommandations basées sur les modèles généraux pré-entraînés.\n",
    "\n",
    "            Affiche les recommandations de manière conviviale, avec les détails des films et les scores prédits.\n",
    "\n",
    "        Gestion de l'état de session (st.session_state) pour maintenir la page active, l'ID utilisateur courant, les nouvelles évaluations en cours de saisie, etc.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise streamlit pour tous les aspects de l'interface graphique.\n",
    "\n",
    "        Utilise constants.py, content.py, recommender.py.\n",
    "\n",
    "        Charge df_items_global et df_ratings_global via loaders.py au démarrage pour avoir les données à jour.\n",
    "\n",
    "        Lit user_profiles.csv pour afficher les noms des utilisateurs dans la liste de sélection.\n",
    "\n",
    "8. merge_new_ratings.py (Nouveau script hors ligne)\n",
    "\n",
    "    Rôle : Script hors ligne pour fusionner les nouvelles évaluations (enregistrées par app.py dans new_ratings_pending.csv) avec le fichier principal des évaluations (ratings.csv).\n",
    "\n",
    "    Processus :\n",
    "\n",
    "        Lit new_ratings_pending.csv.\n",
    "\n",
    "        Lit ratings.csv (le fichier principal).\n",
    "\n",
    "        Concatène les deux DataFrames.\n",
    "\n",
    "        Gère les doublons (par exemple, en conservant la dernière note pour une paire utilisateur-film).\n",
    "\n",
    "        Écrase ratings.csv avec les données fusionnées.\n",
    "\n",
    "        Archive ou supprime new_ratings_pending.csv.\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Utilise constants.py.\n",
    "\n",
    "        Modifie directement ratings.csv, qui est ensuite utilisé par loaders.py et training.py.\n",
    "\n",
    "        Ce script est une étape manuelle (ou automatisée) à exécuter avant de relancer training.py.\n",
    "\n",
    "9. configs.py\n",
    "\n",
    "    Rôle : Semble destiné à contenir des configurations pour l'évaluation des modèles (par exemple, quels modèles évaluer, quelles métriques utiliser, paramètres de division des données).\n",
    "\n",
    "    Contenu typique :\n",
    "\n",
    "        Liste des modèles à évaluer avec leurs hyperparamètres.\n",
    "\n",
    "        Listes de métriques (MAE, RMSE, Hit Rate, Novelty).\n",
    "\n",
    "        Paramètres pour la division des données (taille du jeu de test).\n",
    "\n",
    "        Paramètres pour l'évaluation Leave-One-Out (valeur de N pour le top-N).\n",
    "\n",
    "    Interaction :\n",
    "\n",
    "        Importerait les classes de modèles depuis models.py.\n",
    "\n",
    "        Serait utilisé par un script d'évaluation (par exemple, evaluator.py mentionné dans le diagramme de projet, qui n'est pas encore implémenté ou fourni).\n",
    "\n",
    "Flux de Données et Processus Général :\n",
    "\n",
    "    Préparation Initiale (Hors Ligne) :\n",
    "\n",
    "        Les données brutes (CSV) sont placées dans les répertoires data/small/content et data/small/evidence.\n",
    "\n",
    "    Chargement des Données (Automatique au démarrage des scripts/app) :\n",
    "\n",
    "        loaders.py lit les CSV, les nettoie et les transforme en df_items_global et df_ratings_global.\n",
    "\n",
    "    Entraînement des Modèles (Hors Ligne) :\n",
    "\n",
    "        training.py utilise df_ratings_global et les définitions de models.py pour entraîner les modèles SVD, UserBased, et ContentBased.\n",
    "\n",
    "        Les modèles entraînés sont sauvegardés sous forme de fichiers .p dans data/small/recs.\n",
    "\n",
    "    Interaction Utilisateur via Streamlit (app.py) :\n",
    "\n",
    "        L'application charge les données via loaders.py.\n",
    "\n",
    "        Nouvel Utilisateur :\n",
    "\n",
    "            L'utilisateur fournit son nom et note des films.\n",
    "\n",
    "            app.py sauvegarde ces informations dans new_ratings_pending.csv et user_profiles.csv.\n",
    "\n",
    "        Utilisateur Existant :\n",
    "\n",
    "            L'utilisateur sélectionne son ID.\n",
    "\n",
    "            app.py appelle recommender.py.\n",
    "\n",
    "            recommender.py charge les modèles .p appropriés et génère des recommandations.\n",
    "\n",
    "            app.py affiche ces recommandations.\n",
    "\n",
    "    Mise à Jour des Données et Modèles (Processus Hors Ligne Périodique) :\n",
    "\n",
    "        Étape 1 : Exécuter merge_new_ratings.py pour intégrer les évaluations des nouveaux utilisateurs dans ratings.csv.\n",
    "\n",
    "        Étape 2 : Exécuter training.py pour ré-entraîner tous les modèles généraux avec le ratings.csv mis à jour.\n",
    "\n",
    "        Après ces étapes, au prochain redémarrage ou rechargement de app.py, les nouveaux utilisateurs seront disponibles dans la liste de sélection et bénéficieront des recommandations des modèles mis à jour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a3058",
   "metadata": {},
   "source": [
    "### Description des fichiers et leurs fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c5137",
   "metadata": {},
   "source": [
    "#### constants.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666b7a8",
   "metadata": {},
   "source": [
    "Ce code définit une classe de constantes Constant qui centralise tous les chemins d'accès et noms de colonnes utilisés pour manipuler les données. L'objectif est d'automatiser et d'uniformiser les notations pour tous les fichiers.\n",
    "\n",
    "Cela comprend les chemins vers les fichiers de contenus (movies.csv), d'évidences (ratings.csv), les noms des colonnes importantes (comme userId, movieId, rating), ainsi que l'échelle des notes (de 1 à 5). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d895dc4",
   "metadata": {},
   "source": [
    "#### loaders.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50b639",
   "metadata": {},
   "source": [
    "Ce code sert à charger les données. \n",
    "\n",
    "**load_ratings** et **load_movies** : charger les ratings et les movies sous forme de dataframe \n",
    "Si surprise_format=True, elle convertit les données au format requis par la bibliothèque Surprise, qui est utilisée pour implémenter et évaluer des algorithmes de recommandation collaboratifs.\n",
    "Sinon, elle retourne simplement le fichier des ratings sous forme de DataFrame pandas classique, ce qui est utile pour l'exploration, le prétraitement ou l’analyse descriptive.\n",
    "\n",
    "**export_evaluation_report** : permet d’enregistrer les résultats d’une évaluation (sous forme de DataFrame) dans un fichier CSV, avec un nom basé sur la date du jour pour éviter d’écraser les anciens rapports. Le fichier est sauvegardé dans le dossier défini par C.EVALUATION_PATH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999cede",
   "metadata": {},
   "source": [
    "#### coding1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e48f9d",
   "metadata": {},
   "source": [
    "Ce code effectue l'analyse exploratoire des données de notation dans un système de recommandation. Il commence par charger les jeux de données (notes et films), puis calcule des statistiques descriptives essentielles : nombre de notes, d'utilisateurs, de films, fréquence minimale et maximale de notation par film, valeurs de notes possibles, et nombre de films jamais notés. Ensuite, il visualise la distribution des notations par film pour mettre en évidence la \"long-tail property\", caractéristique fréquente dans les systèmes de recommandation (peu de films très populaires, beaucoup peu notés). Enfin, il construit une matrice creuse (sparse matrix) des interactions utilisateur-film, utile pour les algorithmes collaboratifs, et en calcule la sparsité, c’est-à-dire le taux d'absences d’interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8e8ac",
   "metadata": {},
   "source": [
    "#### models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4949f9c",
   "metadata": {},
   "source": [
    "L’idée de ce fichier est de combiner plusieurs stratégies pour estimer la préférence d’un utilisateur pour un item donné, et de produire des recommandations adaptées. Ce fichier inclut à la fois des modèles simples servant de références, des algorithmes classiques comme la factorisation matricielle (SVD), ainsi qu’un modèle content-based qui exploite des caractéristiques détaillées des items et des méthodes d’apprentissage supervisé pour prédire les notes.\n",
    "\n",
    "**get_top_n** : cette fonction transforme une liste brute de prédictions en une liste organisée des meilleures recommandations pour chaque utilisateur. Elle prend en entrée un ensemble de prédictions (notes estimées par un modèle pour chaque couple utilisateur-item) et retourne pour chaque utilisateur une liste des items les mieux notés selon ces prédictions, limitée à un nombre n choisi. Pour éviter que des prédictions à valeur identique se retrouvent toujours dans le même ordre, la fonction introduit un mélange aléatoire avant de trier par ordre décroissant, ce qui permet d’avoir un comportement plus équitable. Ce mécanisme est utile pour obtenir une liste finale qui pourra être présentée à l’utilisateur.\n",
    "\n",
    "**ModelBaseline1** : cette classe prédit toujours la même note fixe (2) pour tous les utilisateurs et items, servant de référence simple\n",
    "\n",
    "**ModelBaseline2** : cette classe génère des prédictions aléatoires dans la plage des notes possibles, pour simuler un modèle sans apprentissage\n",
    "\n",
    "**ModelBaseline3** : cette classe prédit la moyenne globale des notes observées, ce qui reflète une tendance générale sans personnalisation\n",
    "\n",
    "**ModelBaseline4(SVD)** : implémentation d’un algorithme plus avancé, basée sur la factorisation matricielle dite SVD. Cette méthode cherche à représenter chaque utilisateur et chaque item dans un espace latent de faible dimension, de manière à modéliser les interactions sous-jacentes qui expliquent les évaluations. Lors de l’entraînement, ce modèle apprend ces représentations latentes à partir du jeu de données. Sa méthode estimate utilise ces représentations pour prédire la note qu’un utilisateur donnerait à un item, en calculant un produit scalaire pondéré des vecteurs latents.\n",
    "\n",
    "**ContentBased** : copie du modèle dans le fichier content_based.ipynb -> voir explications là-bas\n",
    "\n",
    "**UserBased** : copie du modèle dans le fichier user_based.ipynb -> voir explications là-bas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fdd85",
   "metadata": {},
   "source": [
    "#### user_based.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ddd8b",
   "metadata": {},
   "source": [
    "//1.Loading Data//\n",
    "Chargement des données, création du trainset et de l'antitest-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492f83c",
   "metadata": {},
   "source": [
    "//2. Explore Surprise's user based algorithm//\n",
    "Ce code met en œuvre un algorithme user-user avec moyennes centrées (KNNWithMeans) à l’aide de la bibliothèque Surprise. Il permet de visualiser les résultats du modèle via une métrique choisie et d'analyser les variations des hyperparamètres.\n",
    "\n",
    "Voici les étapes clés :\n",
    "    Le modèle est entraîné sur l’ensemble d’entraînement trainset.\n",
    "    Une prédiction est ensuite effectuée pour l'utilisateur 11 et le film 364, illustrant l’utilisation du modèle pour une recommandation spécifique.\n",
    "    Une prédiction de masse est ensuite générée sur l'anti-test set (toutes les paires utilisateur-film inconnues), et les 30 premières sont affichées avec la note estimée.\n",
    "    Enfin, la matrice de similarité utilisateur-utilisateur est partiellement affichée pour visualiser comment les utilisateurs sont corrélés entre eux selon l’algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc810f55",
   "metadata": {},
   "source": [
    "//3. Implement and explore a customizable user-based algorithm//\n",
    "Algorithme de Surprise. Le modèle apprend donc une matrice de similarité entre utilisateurs, puis prédit les notes d’un utilisateur pour un film en agissant comme une moyenne pondérée des notes données à ce film par les utilisateurs similaires\n",
    "\n",
    "**__init__(self, k=3, min_k=1, sim_options={}, kwargs)** : permet d'initialiser les paramètres \n",
    "\n",
    "**fit(self, trainset)** : Cette méthode prépare tout ce dont le modèle a besoin pour fonctionner : \n",
    "il stocke le trainset fourni par Surprise \n",
    "puis construit la matrice utilisateur-film ratings_matrix avec des NaN pour les absences de notes\n",
    "puis calcule la matrice de similarité entre utilisateurs selon la méthode choisie (msd, jaccard, etc.)\n",
    "puis calcule les moyennes des notes données par chaque utilisateur (utile comme base de prédiction par défaut ou de correction)\n",
    "\n",
    "**estimate(self, u, i)** : Cette méthode prédit la note que l'utilisateur u pourrait donner à l’item (film) i :\n",
    "Si l’utilisateur ou le film est inconnu, retourne NaN.\n",
    "Utilise la moyenne des notes de l'utilisateur u comme prédiction de base.\n",
    "Cherche tous les autres utilisateurs ayant noté l’item i.\n",
    "Calcule la différence entre leur note et leur propre moyenne, pondérée par leur similarité avec u.\n",
    "Prend les k utilisateurs les plus similaires, et combine leur contribution pour ajuster la prédiction.\n",
    "Si le nombre de voisins valides est supérieur à min_k, la prédiction est retournée ; sinon on garde la moyenne de u.\n",
    "\n",
    "**compute_ratings_matrix(self)** : Crée une matrice dense ratings_matrix, de taille (n_users, n_items), initialisée à NaN. Elle est remplie avec les notes connues du trainset. Elle est utilisée pour comparer les utilisateurs entre eux\n",
    "\n",
    "**compute_similarity_matrix(self)** : Construit la matrice de similarité symétrique entre utilisateurs :\n",
    "Si la méthode est msd (Mean Squared Difference) : compare les notes communes des utilisateurset applique la formule sim = 1 / (1 + MSD) si le support est suffisant.\n",
    "Si la méthode est jaccard : calcule la similarité entre les ensembles de films notés (indépendamment des valeurs de note).\n",
    "\n",
    "Le résultat est une matrice carrée sim de taille (n_users, n_users).\n",
    "\n",
    "**jaccard_similarity(self, row_i, row_j)** : Cette fonction calcule la similarité de Jaccard entre deux utilisateurs en se basant uniquement sur les films qu’ils ont notés (et non sur la note elle-même)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58420a",
   "metadata": {},
   "source": [
    "//4. Compare KNNWithMeans with UserBased//\n",
    "\n",
    "Ce code compare les prédictions du modèle UserBased implémenté manuellement à celles du modèle KNNWithMeans de Surprise, en utilisant les mêmes paramètres de similarité (msd, k=3, min_k=2). L’objectif est de valider que les deux algorithmes produisent des résultats cohérents, ce qui permet de vérifier la justesse de l’implémentation personnalisée du UserBased. Cela sert donc de test d’équivalence entre une version maison et une version de référence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d8db1",
   "metadata": {},
   "source": [
    "//5. Compare MSD and Jaccard//\n",
    "\n",
    "Ce code compare simplement les prédictions faites par la similarité MSD et la similarité Jaccard, tout deux placé dans le modèle UserBased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceed114",
   "metadata": {},
   "source": [
    "#### content_based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa7f08",
   "metadata": {},
   "source": [
    "//Explore and select content features//\n",
    "\n",
    "Ce bloc de code sert à extraire et construire des caractéristiques (features) descriptives à partir des données de films pour enrichir le modèle de recommandation. Il est utilisé pour de la recherche mais pas forcément utile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9dc60",
   "metadata": {},
   "source": [
    "//Build a Content Based Model//\n",
    "\n",
    "**class ContentBased**\n",
    "Ce modèle de recommandation basé sur le contenu apprend une fonction de notation personnalisée pour chaque utilisateur. Il transforme d'abord chaque film en un vecteur de caractéristiques (features) descriptives, puis, pour chaque utilisateur, il entraîne un modèle de régression distinct qui apprend à prédire les notes de cet utilisateur en se basant sur les caractéristiques des films qu'il a déjà évalués.\n",
    "\n",
    "**__init__(self, features_method, regressor_method)** : C'est le constructeur de la classe. Il initialise l'algorithme en stockant les méthodes choisies pour l'extraction des caractéristiques (features_method) et pour le modèle de régression (regressor_method). Il appelle également create_content_features une première fois pour générer le DataFrame global des caractéristiques des items (films), qui sera utilisé par tous les utilisateurs.\n",
    "\n",
    "**create_content_features(self, features_methods)** : Cette fonction est le \"Content Analyzer\". Elle charge les informations sur les items (films) et, en fonction des features_methods spécifiés (ex: \"title_length\", \"Genre_binary\", \"Tags\" avec TF-IDF), elle construit un DataFrame où chaque ligne correspond à un film et chaque colonne à une caractéristique extraite et prétraitée (souvent normalisée).\n",
    "\n",
    "**fit(self, trainset)** : C'est le \"Profile Learner\". Cette méthode entraîne le modèle.\n",
    "\n",
    "    Elle s'assure d'abord que les content_features sont à jour (en les recalculant si nécessaire, bien que dans votre code actuel, elles soient déjà calculées dans __init__).\n",
    "    Elle initialise un dictionnaire user_profile pour stocker un modèle de régression distinct pour chaque utilisateur.\n",
    "    Pour chaque utilisateur du trainset :\n",
    "        Elle récupère les films que l'utilisateur a notés et leurs notes.\n",
    "        Elle associe ces films à leurs caractéristiques (issues de self.content_features).\n",
    "        Elle utilise ces caractéristiques comme variables explicatives (X) et les notes de l'utilisateur comme variable cible (y).\n",
    "        Elle entraîne un modèle de régression (spécifié par self.regressor_method, ex: LinearRegression, RandomForestRegressor) sur ces données spécifiques à l'utilisateur.\n",
    "        Le modèle entraîné pour cet utilisateur est stocké dans self.user_profile[u]. S'il n'y a pas assez de données ou si une méthode de régression n'est pas spécifiée, le profil peut rester None\n",
    "\n",
    "**estimate(self, u, i)** : C'est le \"Scoring Component\". Cette méthode prédit la note qu'un utilisateur u donnerait à un item (film) i. Elle vérifie d'abord si l'utilisateur et l'item sont connus dans le trainset. Si l'user est inconnu (cad si self.user_profile[u] est None, par exemple pour un utilisateur avec peu de notes), elle retourne la note moyenne globale du trainset. Elle récupère les caractéristiques de l'item i à partir de self.content_features. Si l'item n'a pas de caractéristiques (n'est pas dans l'index), elle retourne aussi la moyenne globale.\n",
    "Elle utilise le modèle de régression personnel de l'utilisateur u (stocké dans self.user_profile[u]) pour prédire une note en se basant sur les caractéristiques de l'item i. Elle retourne cette note prédite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efcc27",
   "metadata": {},
   "source": [
    "// Tester pour voir \n",
    "\n",
    "**test_contentbased_class** : Cette fonction test_contentbased_class permet de tester rapidement une implémentation du modèle de recommandation basé sur le contenu (ContentBased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af4ed4",
   "metadata": {},
   "source": [
    "#### configs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c252499",
   "metadata": {},
   "source": [
    "Ce fichier agit comme une interface de configuration centralisée pour automatiser les expériences. Il permet de changer les modèles, méthodes, ou paramètres sans modifier le code principal d’évaluation, ce qui rend le système modulaire et facilement extensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfae2b",
   "metadata": {},
   "source": [
    "#### evaluators.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60637980",
   "metadata": {},
   "source": [
    "\\\\1. Model Validation Functions//\n",
    "\n",
    "**load_ratings(surprise_format=False)** : \n",
    "Cette fonction charge le fichier de ratings (notes données par les utilisateurs aux films).\n",
    "Si surprise_format=True, elle formate les données pour qu’elles soient compatibles avec la bibliothèque Surprise (utilisée pour entraîner les algorithmes de recommandation).\n",
    "Sinon, elle retourne simplement un DataFrame pandas brut.\n",
    "\n",
    "**generate_split_predictions(algo, ratings_dataset, eval_config)** : \n",
    "Cette fonction évalue un modèle à l’aide d’un échantillonnage aléatoire : elle divise les données en un ensemble d'entraînement et un ensemble de test (selon test_size).\n",
    "Elle entraîne l’algorithme (algo) sur les données d’entraînement, puis prédit les notes sur le testset.\n",
    "Les prédictions obtenues sont ensuite utilisées pour calculer des métriques de précision comme MAE ou RMSE.\n",
    "\n",
    "**generate_loo_top_n(algo, ratings_dataset, eval_config)** : \n",
    "Cette fonction utilise la méthode du Leave-One-Out (LOO), qui consiste à cacher une note par utilisateur pour tester la pertinence des recommandations.\n",
    "Après entraînement sur les autres notes, l’algorithme génère des recommandations sur les films non vus.\n",
    "On extrait les top-N recommandations pour chaque utilisateur et on vérifie si l’item retiré en fait partie (ex. via le hit rate).\n",
    "\n",
    "**generate_full_top_n(algo, ratings_dataset, eval_config)** :\n",
    "Ici, l’algorithme est entraîné sur la totalité des données disponibles.\n",
    "Il prédit ensuite les notes sur tous les films que chaque utilisateur n’a jamais notés (anti-testset).\n",
    "On en extrait les top-N recommandations pour chaque utilisateur.\n",
    "Cette approche permet d’évaluer la qualité globale des recommandations, notamment leur originalité (ex : avec la métrique novelty).\n",
    "\n",
    "**precompute_information()** : \n",
    "Cette fonction calcule des informations utiles pour certaines métriques d’évaluation.\n",
    "Elle compte combien de fois chaque film a été noté, puis classe les films par popularité décroissante.\n",
    "Elle crée un dictionnaire item_to_rank qui associe à chaque film son rang (1 = le plus populaire).\n",
    "Ce classement est ensuite utilisé pour évaluer la nouveauté des recommandations (préférer des films moins vus).\n",
    "\n",
    "**create_evaluation_report(eval_config, sp_ratings, precomputed_dict, available_metrics)** : \n",
    "C’est la fonction principale qui orchestre l’évaluation de tous les modèles définis dans EvalConfig.\n",
    "Elle applique successivement les trois types d’évaluation (split, loo, full) et calcule les métriques correspondantes.\n",
    "Pour chaque modèle, elle entraîne l’algorithme, génère les prédictions et appelle les fonctions d’évaluation adéquates.\n",
    "Elle compile tous les résultats dans un DataFrame résumé, prêt à être analysé ou affiché dans un rapport final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d3f68",
   "metadata": {},
   "source": [
    "\\\\2. Evaluation metrics//\n",
    "\n",
    "**get_hit_rate(anti_testset_top_n, testset)** : \n",
    "Cette fonction calcule le hit rate, elle vérifie, pour chaque utilisateur, si le film retiré du jeu de données (et placé dans le testset) apparaît dans ses top-N recommandations (anti_testset_top_n).\n",
    "Un \"hit\" (succès) vaut 1 si le film est retrouvé, sinon c’est un \"fail\" (0).\n",
    "On calcule ensuite la proportion moyenne de succès sur l’ensemble des utilisateurs.\n",
    "C’est une mesure simple mais efficace pour évaluer la capacité du système à retrouver des films pertinents.\n",
    "\n",
    "**get_novelty(anti_testset_top_n, item_to_rank)** : \n",
    "Cette fonction mesure la nouveauté des recommandations en utilisant le rang de popularité des films.\n",
    "Plus un film recommandé est impopulaire (rang élevé), plus il est considéré comme \"novel\" (nouveau).\n",
    "Elle parcourt toutes les recommandations faites aux utilisateurs, additionne les rangs des films et calcule une moyenne.\n",
    "Cette moyenne est ensuite normalisée par le nombre total de films pour donner un score compris entre 0 et 1.\n",
    "Plus le score est élevé, plus le système propose des contenus originaux et rarement vus par les autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64604840",
   "metadata": {},
   "source": [
    "\\\\3. Evaluation workflow//\n",
    "\n",
    "Ce bloc de code sert à évaluer un ou plusieurs modèles de recommandation définis dans EvalConfig à l’aide de différentes métriques. Il commence par charger les données de notation au format Surprise (sp_ratings) et initialise un dictionnaire vide pour les informations pré-calculées (precomputed_dict). Ensuite, la fonction create_evaluation_report est appelée pour entraîner les modèles et calculer les performances selon les métriques définies (comme MAE, RMSE, hit_rate, novelty). Enfin, les résultats sont affichés à l’écran puis exportés grâce à export_evaluation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec36e47",
   "metadata": {},
   "source": [
    "### 📐 Metriques d'évaluations rappel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0467d3e",
   "metadata": {},
   "source": [
    "🔹 1. MAE (Mean Absolute Error) – Erreur absolue moyenne\n",
    "\n",
    "    Objectif : mesurer la précision moyenne des prédictions du système, en regardant à quel point les prédictions sont éloignées des notes réelles.\n",
    "\n",
    "    Formule :\n",
    "    MAE=1N∑i=1N∣r^i−ri∣\n",
    "    MAE=N1​i=1∑N​∣r^i​−ri​∣\n",
    "\n",
    "    où :\n",
    "\n",
    "        r^ir^i​ = note prédite\n",
    "\n",
    "        riri​ = note réelle\n",
    "\n",
    "        NN = nombre total de prédictions\n",
    "\n",
    "    Interprétation :\n",
    "\n",
    "        Plus MAE est proche de 0, plus les prédictions sont précises.\n",
    "\n",
    "        Une MAE de 0.5 signifie que, en moyenne, les prédictions sont à 0.5 point d’écart des vraies notes.\n",
    "\n",
    "🔹 2. RMSE (Root Mean Squared Error) – Racine carrée de l'erreur quadratique moyenne\n",
    "\n",
    "    Objectif : mesurer la précision globale, mais en pénalisant davantage les grandes erreurs.\n",
    "\n",
    "    Formule :\n",
    "    RMSE=1N∑i=1N(r^i−ri)2\n",
    "    RMSE=N1​i=1∑N​(r^i​−ri​)2\n",
    "\n",
    "    ​\n",
    "\n",
    "    Différence avec MAE :\n",
    "\n",
    "        RMSE met plus de poids sur les grosses erreurs.\n",
    "\n",
    "        Exemple : une erreur de 2 compte plus fortement qu’une erreur de 1, car elle est au carré.\n",
    "\n",
    "🔹 3. Hit Rate – Taux de couverture de l’utilisateur\n",
    "\n",
    "    Objectif : mesurer si l’élément que l’utilisateur a réellement aimé est présent dans les recommandations du système.\n",
    "\n",
    "    Utilisé dans : Leave-One-Out (LOO)\n",
    "    On retire un item que l’utilisateur a noté, puis on génère des recommandations, et on regarde s’il est dedans.\n",
    "\n",
    "    Formule :\n",
    "    Hit Rate=Nombre de hitsNombre total de tests\n",
    "    Hit Rate=Nombre total de testsNombre de hits​\n",
    "\n",
    "    Exemple :\n",
    "    Si on fait ça pour 100 utilisateurs, et que dans 75 cas le système a recommandé l’item retiré → Hit Rate = 0.75.\n",
    "\n",
    "    Intérêt :\n",
    "\n",
    "        C’est une métrique binaire : est-ce que l’item \"test\" est dans le top-N recommandations ou non ?\n",
    "\n",
    "        Plus elle est élevée, mieux le système retrouve les goûts passés des utilisateurs.\n",
    "\n",
    "🔹 4. Novelty – Nouveauté\n",
    "\n",
    "    Objectif : évaluer si le système recommande des choses originales, peu connues, plutôt que toujours les mêmes blockbusters.\n",
    "\n",
    "    Pourquoi c’est important ?\n",
    "    Un système qui recommande toujours les films les plus populaires est peu utile à long terme. La \"nouveauté\" incite à la diversité des découvertes.\n",
    "\n",
    "    Comment c’est mesuré ?\n",
    "    Souvent par :\n",
    "\n",
    "        Popularité inverse : plus un film est populaire, moins il est \"novel\".\n",
    "\n",
    "        Calcul basé sur le log du nombre de vues :\n",
    "        Novelty=1∣R∣∑i∈R−log⁡2(p(i))\n",
    "        Novelty=∣R∣1​i∈R∑​−log2​(p(i))\n",
    "\n",
    "        où p(i)p(i) est la probabilité d'apparition de l'item (fréquence), et RR l'ensemble des items recommandés.\n",
    "\n",
    "    Interprétation :\n",
    "\n",
    "        Une valeur plus élevée = des recommandations moins connues, donc plus \"originales\"."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
